<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>R data structure with stringr, forcats, lubridate, and tidyr</title>
    <meta charset="utf-8" />
    <meta name="author" content="John Franchak" />
    <script src="libs/header-attrs-2.11.3/header-attrs.js"></script>
    <link href="libs/tile-view-0.2.6/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view-0.2.6/tile-view.js"></script>
    <script src="libs/js-cookie-3.0.0/js.cookie.js"></script>
    <script src="libs/peerjs-1.3.1/peerjs.min.js"></script>
    <script src="libs/tiny.toast-1.0.0/toast.min.js"></script>
    <link href="libs/xaringanExtra-broadcast-0.2.6/broadcast.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-broadcast-0.2.6/broadcast.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# R data structure with stringr, forcats, lubridate, and tidyr
## PSYC 259: Principles of Data Science
### John Franchak

---







# Today's tutorial

- Working with different data types
  * Vectors and lists
  * Strings
  * Factors
  * Dates
- Tidying data
  * Pivoting from/to wide/long format
  * Binding and joining data
 
.content-box-blue[
&lt;svg viewBox="0 0 496 512" style="height:1em;position:relative;display:inline-block;top:.1em;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"&gt;&lt;/path&gt;&lt;/svg&gt; Follow along from the [Github repo](https://github.com/psych-259-data-science-2022/259-data-structure)
]

.footnote[.small[.bold[Last updated: 2022-01-31]]]

---
# Common data types in R
- Numeric
  * integer: 1, 2, 3
  * double: 1.12124
  
- .brand-red[Character: “hello”]

- Logical: T/F (TRUE/FALSE)

- .brand-red[Datetime]

- .brand-red[Factor]

- .brand-red[Vectors and lists]

---
# What packages do we need?


```r
library(tidyverse)
```

```
── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──
```

```
✓ ggplot2 3.3.5     ✓ purrr   0.3.4
✓ tibble  3.1.6     ✓ dplyr   1.0.7
✓ tidyr   1.1.4     ✓ stringr 1.4.0
✓ readr   2.0.2     ✓ forcats 0.5.1
```

```
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
x dplyr::filter() masks stats::filter()
x dplyr::lag()    masks stats::lag()
```

```r
library(lubridate) #install if needed
```

```

Attaching package: 'lubridate'
```

```
The following objects are masked from 'package:base':

    date, intersect, setdiff, union
```

---
# What packages do we need?

- Default tidyverse
  * `ggplot2`: graphing
  * `tibble`: use tibble-style dataframes
  * `tidyr`: shaping tibbles and columns
  * `purrr`: tools for automation
  * `dplyr`: selecting, filtering, and transforming dataframes
  * `stringr`: functions for manipulating strings
  * `forcats`: functions for manipulating factors
- Extras
  * `lubridate`: functions for manipulating dates

---
# Vectors and lists: Collections of values
- Vectors are type-homogeneous
  * Numeric vectors, `c(1,2,3,4,5)`, `1:5`
  * Character vectors,  `c("Hello", "Goodbye")`
  * Logical vectors, `c(T, T, T, F, T, F)`
  * Vector items can be named `c(x = 1, y = 2)`
- Lists are type-heterogeneous
  * Mix types, `list("1", 1, TRUE, 1:5)`
  * Tibbles are lists of vectors/lists of the same length

---
count: false
 
# Vectors
.panel1-vectors-auto[

```r
*v &lt;- c(1, 2, 3, 4, 5)
```
]
 
.panel2-vectors-auto[

]

---
count: false
 
# Vectors
.panel1-vectors-auto[

```r
v &lt;- c(1, 2, 3, 4, 5)
*v 
```
]
 
.panel2-vectors-auto[

```
[1] 1 2 3 4 5
```
]

---
count: false
 
# Vectors
.panel1-vectors-auto[

```r
v &lt;- c(1, 2, 3, 4, 5)
v
*typeof(v)
```
]
 
.panel2-vectors-auto[

```
[1] 1 2 3 4 5
```

```
[1] "double"
```
]

---
count: false
 
# Vectors
.panel1-vectors-auto[

```r
v &lt;- c(1, 2, 3, 4, 5)
v
typeof(v)
*length(v)
```
]
 
.panel2-vectors-auto[

```
[1] 1 2 3 4 5
```

```
[1] "double"
```

```
[1] 5
```
]

---
count: false
 
# Vectors
.panel1-vectors-auto[

```r
v &lt;- c(1, 2, 3, 4, 5)
v
typeof(v)
length(v)
*v[1]  # Use brackets to access a vector element
```
]
 
.panel2-vectors-auto[

```
[1] 1 2 3 4 5
```

```
[1] "double"
```

```
[1] 5
```

```
[1] 1
```
]

---
count: false
 
# Vectors
.panel1-vectors-auto[

```r
v &lt;- c(1, 2, 3, 4, 5)
v
typeof(v)
length(v)
v[1]  # Use brackets to access a vector element
*v[3]
```
]
 
.panel2-vectors-auto[

```
[1] 1 2 3 4 5
```

```
[1] "double"
```

```
[1] 5
```

```
[1] 1
```

```
[1] 3
```
]

---
count: false
 
# Vectors
.panel1-vectors-auto[

```r
v &lt;- c(1, 2, 3, 4, 5)
v
typeof(v)
length(v)
v[1]  # Use brackets to access a vector element
v[3]
*v &lt;- c(v, 6, 7, 8)  # use c to add items
```
]
 
.panel2-vectors-auto[

```
[1] 1 2 3 4 5
```

```
[1] "double"
```

```
[1] 5
```

```
[1] 1
```

```
[1] 3
```
]

---
count: false
 
# Vectors
.panel1-vectors-auto[

```r
v &lt;- c(1, 2, 3, 4, 5)
v
typeof(v)
length(v)
v[1]  # Use brackets to access a vector element
v[3]
v &lt;- c(v, 6, 7, 8)  # use c to add items
*v &lt;- c(1, 2, 3, "4", "5", "6")
```
]
 
.panel2-vectors-auto[

```
[1] 1 2 3 4 5
```

```
[1] "double"
```

```
[1] 5
```

```
[1] 1
```

```
[1] 3
```
]

---
count: false
 
# Vectors
.panel1-vectors-auto[

```r
v &lt;- c(1, 2, 3, 4, 5)
v
typeof(v)
length(v)
v[1]  # Use brackets to access a vector element
v[3]
v &lt;- c(v, 6, 7, 8)  # use c to add items
v &lt;- c(1, 2, 3, "4", "5", "6")
*v  # You cannot mix types in a vector
```
]
 
.panel2-vectors-auto[

```
[1] 1 2 3 4 5
```

```
[1] "double"
```

```
[1] 5
```

```
[1] 1
```

```
[1] 3
```

```
[1] "1" "2" "3" "4" "5" "6"
```
]

---
count: false
 
# Vectors
.panel1-vectors-auto[

```r
v &lt;- c(1, 2, 3, 4, 5)
v
typeof(v)
length(v)
v[1]  # Use brackets to access a vector element
v[3]
v &lt;- c(v, 6, 7, 8)  # use c to add items
v &lt;- c(1, 2, 3, "4", "5", "6")
v  # You cannot mix types in a vector
*v &lt;- c(x = 1, y = 2, z = 3)  # Named vector
```
]
 
.panel2-vectors-auto[

```
[1] 1 2 3 4 5
```

```
[1] "double"
```

```
[1] 5
```

```
[1] 1
```

```
[1] 3
```

```
[1] "1" "2" "3" "4" "5" "6"
```
]

---
count: false
 
# Vectors
.panel1-vectors-auto[

```r
v &lt;- c(1, 2, 3, 4, 5)
v
typeof(v)
length(v)
v[1]  # Use brackets to access a vector element
v[3]
v &lt;- c(v, 6, 7, 8)  # use c to add items
v &lt;- c(1, 2, 3, "4", "5", "6")
v  # You cannot mix types in a vector
v &lt;- c(x = 1, y = 2, z = 3)  # Named vector
*v 
```
]
 
.panel2-vectors-auto[

```
[1] 1 2 3 4 5
```

```
[1] "double"
```

```
[1] 5
```

```
[1] 1
```

```
[1] 3
```

```
[1] "1" "2" "3" "4" "5" "6"
```

```
x y z 
1 2 3 
```
]

---
count: false
 
# Vectors
.panel1-vectors-auto[

```r
v &lt;- c(1, 2, 3, 4, 5)
v
typeof(v)
length(v)
v[1]  # Use brackets to access a vector element
v[3]
v &lt;- c(v, 6, 7, 8)  # use c to add items
v &lt;- c(1, 2, 3, "4", "5", "6")
v  # You cannot mix types in a vector
v &lt;- c(x = 1, y = 2, z = 3)  # Named vector
v
*v['y']
```
]
 
.panel2-vectors-auto[

```
[1] 1 2 3 4 5
```

```
[1] "double"
```

```
[1] 5
```

```
[1] 1
```

```
[1] 3
```

```
[1] "1" "2" "3" "4" "5" "6"
```

```
x y z 
1 2 3 
```

```
y 
2 
```
]

---
count: false
 
# Vectors
.panel1-vectors-auto[

```r
v &lt;- c(1, 2, 3, 4, 5)
v
typeof(v)
length(v)
v[1]  # Use brackets to access a vector element
v[3]
v &lt;- c(v, 6, 7, 8)  # use c to add items
v &lt;- c(1, 2, 3, "4", "5", "6")
v  # You cannot mix types in a vector
v &lt;- c(x = 1, y = 2, z = 3)  # Named vector
v
v['y']

*files &lt;- list.files(path = "data_raw")
```
]
 
.panel2-vectors-auto[

```
[1] 1 2 3 4 5
```

```
[1] "double"
```

```
[1] 5
```

```
[1] 1
```

```
[1] 3
```

```
[1] "1" "2" "3" "4" "5" "6"
```

```
x y z 
1 2 3 
```

```
y 
2 
```
]

---
count: false
 
# Vectors
.panel1-vectors-auto[

```r
v &lt;- c(1, 2, 3, 4, 5)
v
typeof(v)
length(v)
v[1]  # Use brackets to access a vector element
v[3]
v &lt;- c(v, 6, 7, 8)  # use c to add items
v &lt;- c(1, 2, 3, "4", "5", "6")
v  # You cannot mix types in a vector
v &lt;- c(x = 1, y = 2, z = 3)  # Named vector
v
v['y']

files &lt;- list.files(path = "data_raw")
*files[1]  # Character vector
```
]
 
.panel2-vectors-auto[

```
[1] 1 2 3 4 5
```

```
[1] "double"
```

```
[1] 5
```

```
[1] 1
```

```
[1] 3
```

```
[1] "1" "2" "3" "4" "5" "6"
```

```
x y z 
1 2 3 
```

```
y 
2 
```

```
[1] "vocab12.5.csv"
```
]

---
count: false
 
# Vectors
.panel1-vectors-auto[

```r
v &lt;- c(1, 2, 3, 4, 5)
v
typeof(v)
length(v)
v[1]  # Use brackets to access a vector element
v[3]
v &lt;- c(v, 6, 7, 8)  # use c to add items
v &lt;- c(1, 2, 3, "4", "5", "6")
v  # You cannot mix types in a vector
v &lt;- c(x = 1, y = 2, z = 3)  # Named vector
v
v['y']

files &lt;- list.files(path = "data_raw")
files[1]  # Character vector
*files[2]
```
]
 
.panel2-vectors-auto[

```
[1] 1 2 3 4 5
```

```
[1] "double"
```

```
[1] 5
```

```
[1] 1
```

```
[1] 3
```

```
[1] "1" "2" "3" "4" "5" "6"
```

```
x y z 
1 2 3 
```

```
y 
2 
```

```
[1] "vocab12.5.csv"
```

```
[1] "vocab12.csv"
```
]

---
count: false
 
# Vectors
.panel1-vectors-auto[

```r
v &lt;- c(1, 2, 3, 4, 5)
v
typeof(v)
length(v)
v[1]  # Use brackets to access a vector element
v[3]
v &lt;- c(v, 6, 7, 8)  # use c to add items
v &lt;- c(1, 2, 3, "4", "5", "6")
v  # You cannot mix types in a vector
v &lt;- c(x = 1, y = 2, z = 3)  # Named vector
v
v['y']

files &lt;- list.files(path = "data_raw")
files[1]  # Character vector
files[2]
*length(files)
```
]
 
.panel2-vectors-auto[

```
[1] 1 2 3 4 5
```

```
[1] "double"
```

```
[1] 5
```

```
[1] 1
```

```
[1] 3
```

```
[1] "1" "2" "3" "4" "5" "6"
```

```
x y z 
1 2 3 
```

```
y 
2 
```

```
[1] "vocab12.5.csv"
```

```
[1] "vocab12.csv"
```

```
[1] 24
```
]

&lt;style&gt;
.panel1-vectors-auto {
  color: black;
  width: 65.3333333333333%;
  hight: 32%;
  float: left;
  padding-left: 1%;
  font-size: 80%
}
.panel2-vectors-auto {
  color: black;
  width: 32.6666666666667%;
  hight: 32%;
  float: left;
  padding-left: 1%;
  font-size: 80%
}
.panel3-vectors-auto {
  color: black;
  width: NA%;
  hight: 33%;
  float: left;
  padding-left: 1%;
  font-size: 80%
}
&lt;/style&gt;





---
count: false
 
# Lists
.panel1-lists-auto[

```r
*lt &lt;- list(x = 1, y = "3", z = 1:5)
```
]
 
.panel2-lists-auto[

]

---
count: false
 
# Lists
.panel1-lists-auto[

```r
lt &lt;- list(x = 1, y = "3", z = 1:5)
*lt
```
]
 
.panel2-lists-auto[

```
$x
[1] 1

$y
[1] "3"

$z
[1] 1 2 3 4 5
```
]

---
count: false
 
# Lists
.panel1-lists-auto[

```r
lt &lt;- list(x = 1, y = "3", z = 1:5)
lt
*lt$z # Access named list elements with $  # Access named list elements with $
```
]
 
.panel2-lists-auto[

```
$x
[1] 1

$y
[1] "3"

$z
[1] 1 2 3 4 5
```

```
[1] 1 2 3 4 5
```
]

---
count: false
 
# Lists
.panel1-lists-auto[

```r
lt &lt;- list(x = 1, y = "3", z = 1:5)
lt
lt$z # Access named list elements with $  # Access named list elements with $
*lt[[1]]  # Use double brackets to get list elements
```
]
 
.panel2-lists-auto[

```
$x
[1] 1

$y
[1] "3"

$z
[1] 1 2 3 4 5
```

```
[1] 1 2 3 4 5
```

```
[1] 1
```
]

---
count: false
 
# Lists
.panel1-lists-auto[

```r
lt &lt;- list(x = 1, y = "3", z = 1:5)
lt
lt$z # Access named list elements with $  # Access named list elements with $
lt[[1]]  # Use double brackets to get list elements
*lt[[3]] &lt;- 5:7
```
]
 
.panel2-lists-auto[

```
$x
[1] 1

$y
[1] "3"

$z
[1] 1 2 3 4 5
```

```
[1] 1 2 3 4 5
```

```
[1] 1
```
]

---
count: false
 
# Lists
.panel1-lists-auto[

```r
lt &lt;- list(x = 1, y = "3", z = 1:5)
lt
lt$z # Access named list elements with $  # Access named list elements with $
lt[[1]]  # Use double brackets to get list elements
lt[[3]] &lt;- 5:7

# List of lists
*lt &lt;- list(lt1 = lt, lt2 = lt, lt3 = lt)
```
]
 
.panel2-lists-auto[

```
$x
[1] 1

$y
[1] "3"

$z
[1] 1 2 3 4 5
```

```
[1] 1 2 3 4 5
```

```
[1] 1
```
]

---
count: false
 
# Lists
.panel1-lists-auto[

```r
lt &lt;- list(x = 1, y = "3", z = 1:5)
lt
lt$z # Access named list elements with $  # Access named list elements with $
lt[[1]]  # Use double brackets to get list elements
lt[[3]] &lt;- 5:7

# List of lists
lt &lt;- list(lt1 = lt, lt2 = lt, lt3 = lt)
*lt$lt1
```
]
 
.panel2-lists-auto[

```
$x
[1] 1

$y
[1] "3"

$z
[1] 1 2 3 4 5
```

```
[1] 1 2 3 4 5
```

```
[1] 1
```

```
$x
[1] 1

$y
[1] "3"

$z
[1] 5 6 7
```
]

---
count: false
 
# Lists
.panel1-lists-auto[

```r
lt &lt;- list(x = 1, y = "3", z = 1:5)
lt
lt$z # Access named list elements with $  # Access named list elements with $
lt[[1]]  # Use double brackets to get list elements
lt[[3]] &lt;- 5:7

# List of lists
lt &lt;- list(lt1 = lt, lt2 = lt, lt3 = lt)
lt$lt1

*model &lt;- lm(height ~ mass, data = starwars)
```
]
 
.panel2-lists-auto[

```
$x
[1] 1

$y
[1] "3"

$z
[1] 1 2 3 4 5
```

```
[1] 1 2 3 4 5
```

```
[1] 1
```

```
$x
[1] 1

$y
[1] "3"

$z
[1] 5 6 7
```
]

---
count: false
 
# Lists
.panel1-lists-auto[

```r
lt &lt;- list(x = 1, y = "3", z = 1:5)
lt
lt$z # Access named list elements with $  # Access named list elements with $
lt[[1]]  # Use double brackets to get list elements
lt[[3]] &lt;- 5:7

# List of lists
lt &lt;- list(lt1 = lt, lt2 = lt, lt3 = lt)
lt$lt1

model &lt;- lm(height ~ mass, data = starwars)
*typeof(model)
```
]
 
.panel2-lists-auto[

```
$x
[1] 1

$y
[1] "3"

$z
[1] 1 2 3 4 5
```

```
[1] 1 2 3 4 5
```

```
[1] 1
```

```
$x
[1] 1

$y
[1] "3"

$z
[1] 5 6 7
```

```
[1] "list"
```
]

---
count: false
 
# Lists
.panel1-lists-auto[

```r
lt &lt;- list(x = 1, y = "3", z = 1:5)
lt
lt$z # Access named list elements with $  # Access named list elements with $
lt[[1]]  # Use double brackets to get list elements
lt[[3]] &lt;- 5:7

# List of lists
lt &lt;- list(lt1 = lt, lt2 = lt, lt3 = lt)
lt$lt1

model &lt;- lm(height ~ mass, data = starwars)
typeof(model)
*model$coefficients
```
]
 
.panel2-lists-auto[

```
$x
[1] 1

$y
[1] "3"

$z
[1] 1 2 3 4 5
```

```
[1] 1 2 3 4 5
```

```
[1] 1
```

```
$x
[1] 1

$y
[1] "3"

$z
[1] 5 6 7
```

```
[1] "list"
```

```
 (Intercept)         mass 
171.28536091   0.02807045 
```
]

&lt;style&gt;
.panel1-lists-auto {
  color: black;
  width: 65.3333333333333%;
  hight: 32%;
  float: left;
  padding-left: 1%;
  font-size: 80%
}
.panel2-lists-auto {
  color: black;
  width: 32.6666666666667%;
  hight: 32%;
  float: left;
  padding-left: 1%;
  font-size: 80%
}
.panel3-lists-auto {
  color: black;
  width: NA%;
  hight: 33%;
  float: left;
  padding-left: 1%;
  font-size: 80%
}
&lt;/style&gt;





---
# Character data (strings)

- At minimum, working with characters is needed to deal with file paths

- String functions let you clean up messy text input

- Understanding how to construct and format strings can help you avoid hard-coding things like graph labels and output tables

- Learning how to wrangle strings and exploit patterns helps write more efficient code (e.g., selecting and mutating with `contains()`, `starts_with()`, etc.)

- The `stringr` package has a suite of helper functions for common string operations


---
class: center, middle
background-image: url("stringr.png")
background-size: contain

---
# Jonah's first words

```r
ds$word
```

```
  [1] "book"               "dad"                "cat"               
  [4] "baby"               "socks/shoes"        "banana"            
  [7] "cheese"             "shoes"              "monkey"            
 [10] "hello"              "bear"               "milk/drink"        
 [13] "cleanup"            "grandpa"            "mouth"             
 [16] "coffee"             "agua"               "octopus"           
 [19] "(wrist) watch"      "shower"             "hyena"             
 [22] "heart"              "singing"            "top"               
 [25] "ball"               "dog (animal)"       "llama"             
 [28] "turkey"             "berry"              "apple"             
 [31] "oh no"              "go"                 "car"               
 [34] "that"               "more"               "peacock"           
 [37] "cup"                "hide"               "too"               
 [40] "blanket"            "peanut butter"      "running"           
 [43] "empty"              "that one"           "sandal"            
 [46] "bye bye"            "beep"               "hi"                
 [49] "box"                "night-night"        "jacket"            
 [52] "dinosaur"           "wow"                "snack/food"        
 [55] "wash"               "stroller"           "shark"             
 [58] "grandma"            "face"               "lemon"             
 [61] "potty"              "the end"            "over there"        
 [64] "make"               "diaper"             "bubble"            
 [67] "fish"               "tea"                "peekaboo"          
 [70] "mama"               "keys"               "yellow"            
 [73] "pasta"              "spoon"              "light"             
 [76] "button"             "penis"              "finger"            
 [79] "this one"           "both"               "teeth"             
 [82] "mmmm"               "lion"               "google"            
 [85] "trash"              "cow"                "broccoli"          
 [88] "yogurt"             "outside"            "toy"               
 [91] "train"              "spaghetti"          "stairs"            
 [94] "black"              "wipe"               "loud"              
 [97] "uhoh"               "stick"              "hat"               
[100] "elephant"           "no"                 "yeah"              
[103] "zebra"              "circle"             "lap"               
[106] "towel"              "back"               "oatmeal"           
[109] "xylophone"          "crib"               "where"             
[112] "sticker"            "cookie"             "[eating sound]"    
[115] "bee"                "tree"               "high five"         
[118] "eat"                "plate"              "plane"             
[121] "olive"              "pepper (vegetable)" "cough"             
[124] "dolphin"            "lay down"           "poop"              
[127] "done"               "rabbit"             "(fist) bump"       
[130] "up"                 "tray"               "people"            
[133] "ice cream"          "animal"             "window"            
[136] "letter"             "walrus"             "nose"              
[139] "hippo"              "tissue"             "bread"             
[142] "girl"               "orange (color)"     "frog"              
[145] "rice"               "art"                "marker"            
[148] "number"             "kicking"            "bag"               
[151] "gentle"             "pig"                "pear"              
[154] "horse"              "here"               "soap"              
[157] "pee"                "mine"               "drum"              
[160] "goes"               "shorts"             "gentle"            
[163] "owl"                "bird"               "cereal"            
[166] "flower"             "school"             "mirror"            
[169] "(finger) nail"      "lip"                "music"             
[172] "hold"               "bite"               "thank you"         
[175] "zebra"              "squirrel"           "spider"            
[178] "kiwi"               "read"               "picture"           
[181] "bless you"          "spatula"            "clock"             
[184] "happy"              "racoon"             "house"             
[187] "pancake"            "bumblebee"          "watermelon"        
[190] "wheel"              "computer"           "snake"             
[193] "wet"                "dark"               "curtain"           
[196] "Jonah"              "paper"              "cheek"             
[199] "shirt"              "big"                "roll (v)"          
[202] "guitar"             "zuchinni"           "broken"            
[205] "rhino"              "pork"               "belly"             
[208] "help"               "sheep"              "dip"               
[211] "butterfly"          "bless you"          "skateboard"        
[214] "woof"               "move"               "cap"               
[217] "juice"              "cracker"            "down"              
[220] "bamba"              "do it"              "little"            
[223] "hot"                "alligator"          "pocket"            
[226] "clip"               "everybody"          "close"             
[229] "bib"                "slide"              "laundry"           
[232] "away"               "boat"               "green"             
[235] "stop"               "meow"               "bed"               
[238] "gone"               "fit"                "wash"              
[241] "open"               "toes"               "penguin"           
[244] "fork"               "red"                "piece"             
[247] "oink"               "pepper (spice)"     "garbage"           
[250] "working"            "yay"                "cheers"            
[253] "bus"                "feet"               "balloon"           
[256] "duckie"             "roar"               "vacuum"            
[259] "upside down"        "ravioli"            "sleep sack"        
[262] "egg"                "pants"              "goose"             
[265] "clap"               "mail"               "moo"               
[268] "friend"             "knife"              "farm"              
[271] "couch"              "color"              "cactus"            
[274] "drink"              "taco"               "tortilla"          
[277] "castle"             "dolphin"            "please"            
[280] "right there"        "chicken"            "chair"             
[283] "hand"               "towel"              "sweep"             
[286] "breakfast"          "crab"               "count"             
[289] "market"             "booger"             "carrot"            
[292] "orange (fruit)"     "rail"               "robot"             
[295] "chili"              "star"               "noodle"            
[298] "castle"             "bathroom"           "cheers"            
[301] "ear"                "rock"               "shopping"          
[304] "tower"              "alright"            "green bean"        
[307] "wiggle"             "(eye) gunk"         "avocado"           
[310] "exercise"           "jumping"            "tail"              
[313] "tent"               "snail"              "blueberry"         
[316] "loud"               "nectarine"          "hug"               
[319] "glasses"            "home"               "brush"             
[322] "(guitar) pick"      "bike"               "pajamas"           
[325] "pouch"              "grape"              "footloose"         
[328] "page"               "phone"              "puzzle"            
[331] "stove"              "reach"              "throw"             
[334] "kitchen"            "kiss"               "swim"              
[337] "climb"              "happy"              "haircut"           
[340] "walk"               "leaf"               "park"              
[343] "white"              "that way"           "teacher"           
[346] "elbow"              "hair"               "table"             
[349] "umbrella"           "coaster"            "bug"               
[352] "show"               "fall down"          "boy"               
[355] "pull"               "[gorilla sound]"    "basket"            
[358] "toast"              "three"              "this"              
[361] "purple"             "neigh"              "magnet"            
[364] "upstairs"           "like"               "turn"              
[367] "pillow"             "baa"                "kale"              
[370] "plum"               "excuse me"          "get"               
[373] "out"                "button"             "time"              
[376] "tiger"              "barn"               "pink"              
[379] "nurse"              "tv"                 "dishes"            
[382] "sauce"              "catch"              "sun"               
[385] "sheet"              "rooster"            "dishwasher"        
[388] "tomato"             "panda"              "got it"            
[391] "sky"                "all"                "shut"              
[394] "change"             "shoulder"           "driving"           
[397] "off"                "cooking"            "elbow"             
[400] "found it"           "on"                 "belly button"      
[403] "family"             "moon"               "watch (v)"         
[406] "polar bear"         "camera"             "pumpkin"           
[409] "bounce"             "see"                "thumb"             
[412] "playground"         "ice"                "leopard"           
[415] "swing"              "push"               "messy"             
[418] "goat"               "ride"               "camel"             
[421] "carpet"             "sound"              "fast"              
[424] "napkin"             "tickle"             "soft"              
[427] "fox"                "crayon"             "cut"               
[430] "cry"                "play"               "rocket"            
[433] "pot"                "floor"              "two"               
[436] "dry"                "bottle"             "new"               
[439] "spicy"              "spin"              
```

---
# Length, containing strings, counting strings

```r
ds %&gt;% mutate(word_len = str_length(word), 
              has_b = str_detect(word, "b"), 
              num_b = str_count(word, "b"))
```

```
# A tibble: 440 × 5
   age   word        word_len has_b num_b
   &lt;chr&gt; &lt;chr&gt;          &lt;int&gt; &lt;lgl&gt; &lt;int&gt;
 1 12    book               4 TRUE      1
 2 12.5  dad                3 FALSE     0
 3 13.5  cat                3 FALSE     0
 4 14    baby               4 TRUE      2
 5 14.5  socks/shoes       11 FALSE     0
 6 15    banana             6 TRUE      1
 7 15.5  cheese             6 FALSE     0
 8 16    shoes              5 FALSE     0
 9 16.5  monkey             6 FALSE     0
10 17    hello              5 FALSE     0
# … with 430 more rows
```

---
class: center, middle
background-image: url("regx.png")
background-size: contain

---
count: false
 
# Matching patterns
.panel1-patterns-rotate[

```r
*ds %&gt;% mutate(word_cleaned = str_remove_all(word, "[:punct:]"))
```
]
 
.panel2-patterns-rotate[

```
# A tibble: 440 × 3
   age   word        word_cleaned
   &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;       
 1 12    book        book        
 2 12.5  dad         dad         
 3 13.5  cat         cat         
 4 14    baby        baby        
 5 14.5  socks/shoes socksshoes  
 6 15    banana      banana      
 7 15.5  cheese      cheese      
 8 16    shoes       shoes       
 9 16.5  monkey      monkey      
10 17    hello       hello       
# … with 430 more rows
```
]

---
count: false
 
# Matching patterns
.panel1-patterns-rotate[

```r
*ds %&gt;% mutate(word_cleaned = str_replace_all(word, "[:punct:]"," "))
```
]
 
.panel2-patterns-rotate[

```
# A tibble: 440 × 3
   age   word        word_cleaned
   &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;       
 1 12    book        book        
 2 12.5  dad         dad         
 3 13.5  cat         cat         
 4 14    baby        baby        
 5 14.5  socks/shoes socks shoes 
 6 15    banana      banana      
 7 15.5  cheese      cheese      
 8 16    shoes       shoes       
 9 16.5  monkey      monkey      
10 17    hello       hello       
# … with 430 more rows
```
]

---
count: false
 
# Matching patterns
.panel1-patterns-rotate[

```r
*ds %&gt;% mutate(vowel_count = str_count(word, "[aeiou]"))
```
]
 
.panel2-patterns-rotate[

```
# A tibble: 440 × 3
   age   word        vowel_count
   &lt;chr&gt; &lt;chr&gt;             &lt;int&gt;
 1 12    book                  2
 2 12.5  dad                   1
 3 13.5  cat                   1
 4 14    baby                  1
 5 14.5  socks/shoes           3
 6 15    banana                3
 7 15.5  cheese                3
 8 16    shoes                 2
 9 16.5  monkey                2
10 17    hello                 2
# … with 430 more rows
```
]

---
count: false
 
# Matching patterns
.panel1-patterns-rotate[

```r
*ds %&gt;% mutate(is_three_letter = str_detect(word, "[:alnum:{3}]"))
```
]
 
.panel2-patterns-rotate[

```
# A tibble: 440 × 3
   age   word        is_three_letter
   &lt;chr&gt; &lt;chr&gt;       &lt;lgl&gt;          
 1 12    book        FALSE          
 2 12.5  dad         TRUE           
 3 13.5  cat         TRUE           
 4 14    baby        TRUE           
 5 14.5  socks/shoes FALSE          
 6 15    banana      TRUE           
 7 15.5  cheese      FALSE          
 8 16    shoes       FALSE          
 9 16.5  monkey      TRUE           
10 17    hello       TRUE           
# … with 430 more rows
```
]

&lt;style&gt;
.panel1-patterns-rotate {
  color: black;
  width: 90.4615384615385%;
  hight: 32%;
  float: none;
  padding-left: 1%;
  font-size: 80%
}
.panel2-patterns-rotate {
  color: black;
  width: 7.53846153846154%;
  hight: 32%;
  float: none;
  padding-left: 1%;
  font-size: 80%
}
.panel3-patterns-rotate {
  color: black;
  width: NA%;
  hight: 33%;
  float: none;
  padding-left: 1%;
  font-size: 80%
}
&lt;/style&gt;





---

```r
fnames &lt;- list.files(path="data_raw", full.names = T)
print(fnames)
```

```
 [1] "data_raw/vocab12.5.csv" "data_raw/vocab12.csv"   "data_raw/vocab13.5.csv"
 [4] "data_raw/vocab14.5.csv" "data_raw/vocab14.csv"   "data_raw/vocab15.5.csv"
 [7] "data_raw/vocab15.csv"   "data_raw/vocab16.5.csv" "data_raw/vocab16.csv"  
[10] "data_raw/vocab17.5.csv" "data_raw/vocab17.csv"   "data_raw/vocab18.5.csv"
[13] "data_raw/vocab18.csv"   "data_raw/vocab19.5.csv" "data_raw/vocab19.csv"  
[16] "data_raw/vocab20.5.csv" "data_raw/vocab20.csv"   "data_raw/vocab21.5.csv"
[19] "data_raw/vocab21.csv"   "data_raw/vocab22.5.csv" "data_raw/vocab22.csv"  
[22] "data_raw/vocab23.5.csv" "data_raw/vocab23.csv"   "data_raw/vocab24.csv"  
```

---

count: false
 
# Matching patterns
.panel1-morepatterns-rotate[

```r
fnames &lt;- list.files(path="data_raw", full.names = T)
*str_split(fnames, "/")
```
]
 
.panel2-morepatterns-rotate[

```
[[1]]
[1] "data_raw"      "vocab12.5.csv"

[[2]]
[1] "data_raw"    "vocab12.csv"

[[3]]
[1] "data_raw"      "vocab13.5.csv"

[[4]]
[1] "data_raw"      "vocab14.5.csv"

[[5]]
[1] "data_raw"    "vocab14.csv"

[[6]]
[1] "data_raw"      "vocab15.5.csv"

[[7]]
[1] "data_raw"    "vocab15.csv"

[[8]]
[1] "data_raw"      "vocab16.5.csv"

[[9]]
[1] "data_raw"    "vocab16.csv"

[[10]]
[1] "data_raw"      "vocab17.5.csv"

[[11]]
[1] "data_raw"    "vocab17.csv"

[[12]]
[1] "data_raw"      "vocab18.5.csv"

[[13]]
[1] "data_raw"    "vocab18.csv"

[[14]]
[1] "data_raw"      "vocab19.5.csv"

[[15]]
[1] "data_raw"    "vocab19.csv"

[[16]]
[1] "data_raw"      "vocab20.5.csv"

[[17]]
[1] "data_raw"    "vocab20.csv"

[[18]]
[1] "data_raw"      "vocab21.5.csv"

[[19]]
[1] "data_raw"    "vocab21.csv"

[[20]]
[1] "data_raw"      "vocab22.5.csv"

[[21]]
[1] "data_raw"    "vocab22.csv"

[[22]]
[1] "data_raw"      "vocab23.5.csv"

[[23]]
[1] "data_raw"    "vocab23.csv"

[[24]]
[1] "data_raw"    "vocab24.csv"
```
]

---
count: false
 
# Matching patterns
.panel1-morepatterns-rotate[

```r
fnames &lt;- list.files(path="data_raw", full.names = T)
*str_replace_all(fnames, "data_raw/|.csv|vocab","")
```
]
 
.panel2-morepatterns-rotate[

```
 [1] "12.5" "12"   "13.5" "14.5" "14"   "15.5" "15"   "16.5" "16"   "17.5"
[11] "17"   "18.5" "18"   "19.5" "19"   "20.5" "20"   "21.5" "21"   "22.5"
[21] "22"   "23.5" "23"   "24"  
```
]

---
count: false
 
# Matching patterns
.panel1-morepatterns-rotate[

```r
fnames &lt;- list.files(path="data_raw", full.names = T)
*str_extract_all(fnames, "\\d{2}.\\d{1}|\\d{2}", simplify = T)
```
]
 
.panel2-morepatterns-rotate[

```
      [,1]  
 [1,] "12.5"
 [2,] "12"  
 [3,] "13.5"
 [4,] "14.5"
 [5,] "14"  
 [6,] "15.5"
 [7,] "15"  
 [8,] "16.5"
 [9,] "16"  
[10,] "17.5"
[11,] "17"  
[12,] "18.5"
[13,] "18"  
[14,] "19.5"
[15,] "19"  
[16,] "20.5"
[17,] "20"  
[18,] "21.5"
[19,] "21"  
[20,] "22.5"
[21,] "22"  
[22,] "23.5"
[23,] "23"  
[24,] "24"  
```
]

---
count: false
 
# Matching patterns
.panel1-morepatterns-rotate[

```r
fnames &lt;- list.files(path="data_raw", full.names = T)
*str_extract_all(fnames, "\\.[:alpha:]{1,4}", simplify = T)
```
]
 
.panel2-morepatterns-rotate[

```
      [,1]  
 [1,] ".csv"
 [2,] ".csv"
 [3,] ".csv"
 [4,] ".csv"
 [5,] ".csv"
 [6,] ".csv"
 [7,] ".csv"
 [8,] ".csv"
 [9,] ".csv"
[10,] ".csv"
[11,] ".csv"
[12,] ".csv"
[13,] ".csv"
[14,] ".csv"
[15,] ".csv"
[16,] ".csv"
[17,] ".csv"
[18,] ".csv"
[19,] ".csv"
[20,] ".csv"
[21,] ".csv"
[22,] ".csv"
[23,] ".csv"
[24,] ".csv"
```
]

---
count: false
 
# Matching patterns
.panel1-morepatterns-rotate[

```r
fnames &lt;- list.files(path="data_raw", full.names = T)
*str_extract_all(ds$word, boundary("word"), simplify = T)
```
]
 
.panel2-morepatterns-rotate[

```
       [,1]         [,2]       
  [1,] "book"       ""         
  [2,] "dad"        ""         
  [3,] "cat"        ""         
  [4,] "baby"       ""         
  [5,] "socks"      "shoes"    
  [6,] "banana"     ""         
  [7,] "cheese"     ""         
  [8,] "shoes"      ""         
  [9,] "monkey"     ""         
 [10,] "hello"      ""         
 [11,] "bear"       ""         
 [12,] "milk"       "drink"    
 [13,] "cleanup"    ""         
 [14,] "grandpa"    ""         
 [15,] "mouth"      ""         
 [16,] "coffee"     ""         
 [17,] "agua"       ""         
 [18,] "octopus"    ""         
 [19,] "wrist"      "watch"    
 [20,] "shower"     ""         
 [21,] "hyena"      ""         
 [22,] "heart"      ""         
 [23,] "singing"    ""         
 [24,] "top"        ""         
 [25,] "ball"       ""         
 [26,] "dog"        "animal"   
 [27,] "llama"      ""         
 [28,] "turkey"     ""         
 [29,] "berry"      ""         
 [30,] "apple"      ""         
 [31,] "oh"         "no"       
 [32,] "go"         ""         
 [33,] "car"        ""         
 [34,] "that"       ""         
 [35,] "more"       ""         
 [36,] "peacock"    ""         
 [37,] "cup"        ""         
 [38,] "hide"       ""         
 [39,] "too"        ""         
 [40,] "blanket"    ""         
 [41,] "peanut"     "butter"   
 [42,] "running"    ""         
 [43,] "empty"      ""         
 [44,] "that"       "one"      
 [45,] "sandal"     ""         
 [46,] "bye"        "bye"      
 [47,] "beep"       ""         
 [48,] "hi"         ""         
 [49,] "box"        ""         
 [50,] "night"      "night"    
 [51,] "jacket"     ""         
 [52,] "dinosaur"   ""         
 [53,] "wow"        ""         
 [54,] "snack"      "food"     
 [55,] "wash"       ""         
 [56,] "stroller"   ""         
 [57,] "shark"      ""         
 [58,] "grandma"    ""         
 [59,] "face"       ""         
 [60,] "lemon"      ""         
 [61,] "potty"      ""         
 [62,] "the"        "end"      
 [63,] "over"       "there"    
 [64,] "make"       ""         
 [65,] "diaper"     ""         
 [66,] "bubble"     ""         
 [67,] "fish"       ""         
 [68,] "tea"        ""         
 [69,] "peekaboo"   ""         
 [70,] "mama"       ""         
 [71,] "keys"       ""         
 [72,] "yellow"     ""         
 [73,] "pasta"      ""         
 [74,] "spoon"      ""         
 [75,] "light"      ""         
 [76,] "button"     ""         
 [77,] "penis"      ""         
 [78,] "finger"     ""         
 [79,] "this"       "one"      
 [80,] "both"       ""         
 [81,] "teeth"      ""         
 [82,] "mmmm"       ""         
 [83,] "lion"       ""         
 [84,] "google"     ""         
 [85,] "trash"      ""         
 [86,] "cow"        ""         
 [87,] "broccoli"   ""         
 [88,] "yogurt"     ""         
 [89,] "outside"    ""         
 [90,] "toy"        ""         
 [91,] "train"      ""         
 [92,] "spaghetti"  ""         
 [93,] "stairs"     ""         
 [94,] "black"      ""         
 [95,] "wipe"       ""         
 [96,] "loud"       ""         
 [97,] "uhoh"       ""         
 [98,] "stick"      ""         
 [99,] "hat"        ""         
[100,] "elephant"   ""         
[101,] "no"         ""         
[102,] "yeah"       ""         
[103,] "zebra"      ""         
[104,] "circle"     ""         
[105,] "lap"        ""         
[106,] "towel"      ""         
[107,] "back"       ""         
[108,] "oatmeal"    ""         
[109,] "xylophone"  ""         
[110,] "crib"       ""         
[111,] "where"      ""         
[112,] "sticker"    ""         
[113,] "cookie"     ""         
[114,] "eating"     "sound"    
[115,] "bee"        ""         
[116,] "tree"       ""         
[117,] "high"       "five"     
[118,] "eat"        ""         
[119,] "plate"      ""         
[120,] "plane"      ""         
[121,] "olive"      ""         
[122,] "pepper"     "vegetable"
[123,] "cough"      ""         
[124,] "dolphin"    ""         
[125,] "lay"        "down"     
[126,] "poop"       ""         
[127,] "done"       ""         
[128,] "rabbit"     ""         
[129,] "fist"       "bump"     
[130,] "up"         ""         
[131,] "tray"       ""         
[132,] "people"     ""         
[133,] "ice"        "cream"    
[134,] "animal"     ""         
[135,] "window"     ""         
[136,] "letter"     ""         
[137,] "walrus"     ""         
[138,] "nose"       ""         
[139,] "hippo"      ""         
[140,] "tissue"     ""         
[141,] "bread"      ""         
[142,] "girl"       ""         
[143,] "orange"     "color"    
[144,] "frog"       ""         
[145,] "rice"       ""         
[146,] "art"        ""         
[147,] "marker"     ""         
[148,] "number"     ""         
[149,] "kicking"    ""         
[150,] "bag"        ""         
[151,] "gentle"     ""         
[152,] "pig"        ""         
[153,] "pear"       ""         
[154,] "horse"      ""         
[155,] "here"       ""         
[156,] "soap"       ""         
[157,] "pee"        ""         
[158,] "mine"       ""         
[159,] "drum"       ""         
[160,] "goes"       ""         
[161,] "shorts"     ""         
[162,] "gentle"     ""         
[163,] "owl"        ""         
[164,] "bird"       ""         
[165,] "cereal"     ""         
[166,] "flower"     ""         
[167,] "school"     ""         
[168,] "mirror"     ""         
[169,] "finger"     "nail"     
[170,] "lip"        ""         
[171,] "music"      ""         
[172,] "hold"       ""         
[173,] "bite"       ""         
[174,] "thank"      "you"      
[175,] "zebra"      ""         
[176,] "squirrel"   ""         
[177,] "spider"     ""         
[178,] "kiwi"       ""         
[179,] "read"       ""         
[180,] "picture"    ""         
[181,] "bless"      "you"      
[182,] "spatula"    ""         
[183,] "clock"      ""         
[184,] "happy"      ""         
[185,] "racoon"     ""         
[186,] "house"      ""         
[187,] "pancake"    ""         
[188,] "bumblebee"  ""         
[189,] "watermelon" ""         
[190,] "wheel"      ""         
[191,] "computer"   ""         
[192,] "snake"      ""         
[193,] "wet"        ""         
[194,] "dark"       ""         
[195,] "curtain"    ""         
[196,] "Jonah"      ""         
[197,] "paper"      ""         
[198,] "cheek"      ""         
[199,] "shirt"      ""         
[200,] "big"        ""         
[201,] "roll"       "v"        
[202,] "guitar"     ""         
[203,] "zuchinni"   ""         
[204,] "broken"     ""         
[205,] "rhino"      ""         
[206,] "pork"       ""         
[207,] "belly"      ""         
[208,] "help"       ""         
[209,] "sheep"      ""         
[210,] "dip"        ""         
[211,] "butterfly"  ""         
[212,] "bless"      "you"      
[213,] "skateboard" ""         
[214,] "woof"       ""         
[215,] "move"       ""         
[216,] "cap"        ""         
[217,] "juice"      ""         
[218,] "cracker"    ""         
[219,] "down"       ""         
[220,] "bamba"      ""         
[221,] "do"         "it"       
[222,] "little"     ""         
[223,] "hot"        ""         
[224,] "alligator"  ""         
[225,] "pocket"     ""         
[226,] "clip"       ""         
[227,] "everybody"  ""         
[228,] "close"      ""         
[229,] "bib"        ""         
[230,] "slide"      ""         
[231,] "laundry"    ""         
[232,] "away"       ""         
[233,] "boat"       ""         
[234,] "green"      ""         
[235,] "stop"       ""         
[236,] "meow"       ""         
[237,] "bed"        ""         
[238,] "gone"       ""         
[239,] "fit"        ""         
[240,] "wash"       ""         
[241,] "open"       ""         
[242,] "toes"       ""         
[243,] "penguin"    ""         
[244,] "fork"       ""         
[245,] "red"        ""         
[246,] "piece"      ""         
[247,] "oink"       ""         
[248,] "pepper"     "spice"    
[249,] "garbage"    ""         
[250,] "working"    ""         
[251,] "yay"        ""         
[252,] "cheers"     ""         
[253,] "bus"        ""         
[254,] "feet"       ""         
[255,] "balloon"    ""         
[256,] "duckie"     ""         
[257,] "roar"       ""         
[258,] "vacuum"     ""         
[259,] "upside"     "down"     
[260,] "ravioli"    ""         
[261,] "sleep"      "sack"     
[262,] "egg"        ""         
[263,] "pants"      ""         
[264,] "goose"      ""         
[265,] "clap"       ""         
[266,] "mail"       ""         
[267,] "moo"        ""         
[268,] "friend"     ""         
[269,] "knife"      ""         
[270,] "farm"       ""         
[271,] "couch"      ""         
[272,] "color"      ""         
[273,] "cactus"     ""         
[274,] "drink"      ""         
[275,] "taco"       ""         
[276,] "tortilla"   ""         
[277,] "castle"     ""         
[278,] "dolphin"    ""         
[279,] "please"     ""         
[280,] "right"      "there"    
[281,] "chicken"    ""         
[282,] "chair"      ""         
[283,] "hand"       ""         
[284,] "towel"      ""         
[285,] "sweep"      ""         
[286,] "breakfast"  ""         
[287,] "crab"       ""         
[288,] "count"      ""         
[289,] "market"     ""         
[290,] "booger"     ""         
[291,] "carrot"     ""         
[292,] "orange"     "fruit"    
[293,] "rail"       ""         
[294,] "robot"      ""         
[295,] "chili"      ""         
[296,] "star"       ""         
[297,] "noodle"     ""         
[298,] "castle"     ""         
[299,] "bathroom"   ""         
[300,] "cheers"     ""         
[301,] "ear"        ""         
[302,] "rock"       ""         
[303,] "shopping"   ""         
[304,] "tower"      ""         
[305,] "alright"    ""         
[306,] "green"      "bean"     
[307,] "wiggle"     ""         
[308,] "eye"        "gunk"     
[309,] "avocado"    ""         
[310,] "exercise"   ""         
[311,] "jumping"    ""         
[312,] "tail"       ""         
[313,] "tent"       ""         
[314,] "snail"      ""         
[315,] "blueberry"  ""         
[316,] "loud"       ""         
[317,] "nectarine"  ""         
[318,] "hug"        ""         
[319,] "glasses"    ""         
[320,] "home"       ""         
[321,] "brush"      ""         
[322,] "guitar"     "pick"     
[323,] "bike"       ""         
[324,] "pajamas"    ""         
[325,] "pouch"      ""         
[326,] "grape"      ""         
[327,] "footloose"  ""         
[328,] "page"       ""         
[329,] "phone"      ""         
[330,] "puzzle"     ""         
[331,] "stove"      ""         
[332,] "reach"      ""         
[333,] "throw"      ""         
[334,] "kitchen"    ""         
[335,] "kiss"       ""         
[336,] "swim"       ""         
[337,] "climb"      ""         
[338,] "happy"      ""         
[339,] "haircut"    ""         
[340,] "walk"       ""         
[341,] "leaf"       ""         
[342,] "park"       ""         
[343,] "white"      ""         
[344,] "that"       "way"      
[345,] "teacher"    ""         
[346,] "elbow"      ""         
[347,] "hair"       ""         
[348,] "table"      ""         
[349,] "umbrella"   ""         
[350,] "coaster"    ""         
[351,] "bug"        ""         
[352,] "show"       ""         
[353,] "fall"       "down"     
[354,] "boy"        ""         
[355,] "pull"       ""         
[356,] "gorilla"    "sound"    
[357,] "basket"     ""         
[358,] "toast"      ""         
[359,] "three"      ""         
[360,] "this"       ""         
[361,] "purple"     ""         
[362,] "neigh"      ""         
[363,] "magnet"     ""         
[364,] "upstairs"   ""         
[365,] "like"       ""         
[366,] "turn"       ""         
[367,] "pillow"     ""         
[368,] "baa"        ""         
[369,] "kale"       ""         
[370,] "plum"       ""         
[371,] "excuse"     "me"       
[372,] "get"        ""         
[373,] "out"        ""         
[374,] "button"     ""         
[375,] "time"       ""         
[376,] "tiger"      ""         
[377,] "barn"       ""         
[378,] "pink"       ""         
[379,] "nurse"      ""         
[380,] "tv"         ""         
[381,] "dishes"     ""         
[382,] "sauce"      ""         
[383,] "catch"      ""         
[384,] "sun"        ""         
[385,] "sheet"      ""         
[386,] "rooster"    ""         
[387,] "dishwasher" ""         
[388,] "tomato"     ""         
[389,] "panda"      ""         
[390,] "got"        "it"       
[391,] "sky"        ""         
[392,] "all"        ""         
[393,] "shut"       ""         
[394,] "change"     ""         
[395,] "shoulder"   ""         
[396,] "driving"    ""         
[397,] "off"        ""         
[398,] "cooking"    ""         
[399,] "elbow"      ""         
[400,] "found"      "it"       
[401,] "on"         ""         
[402,] "belly"      "button"   
[403,] "family"     ""         
[404,] "moon"       ""         
[405,] "watch"      "v"        
[406,] "polar"      "bear"     
[407,] "camera"     ""         
[408,] "pumpkin"    ""         
[409,] "bounce"     ""         
[410,] "see"        ""         
[411,] "thumb"      ""         
[412,] "playground" ""         
[413,] "ice"        ""         
[414,] "leopard"    ""         
[415,] "swing"      ""         
[416,] "push"       ""         
[417,] "messy"      ""         
[418,] "goat"       ""         
[419,] "ride"       ""         
[420,] "camel"      ""         
[421,] "carpet"     ""         
[422,] "sound"      ""         
[423,] "fast"       ""         
[424,] "napkin"     ""         
[425,] "tickle"     ""         
[426,] "soft"       ""         
[427,] "fox"        ""         
[428,] "crayon"     ""         
[429,] "cut"        ""         
[430,] "cry"        ""         
[431,] "play"       ""         
[432,] "rocket"     ""         
[433,] "pot"        ""         
[434,] "floor"      ""         
[435,] "two"        ""         
[436,] "dry"        ""         
[437,] "bottle"     ""         
[438,] "new"        ""         
[439,] "spicy"      ""         
[440,] "spin"       ""         
```
]

&lt;style&gt;
.panel1-morepatterns-rotate {
  color: black;
  width: 90.4615384615385%;
  hight: 32%;
  float: none;
  padding-left: 1%;
  font-size: 80%
}
.panel2-morepatterns-rotate {
  color: black;
  width: 7.53846153846154%;
  hight: 32%;
  float: none;
  padding-left: 1%;
  font-size: 80%
}
.panel3-morepatterns-rotate {
  color: black;
  width: NA%;
  hight: 33%;
  float: none;
  padding-left: 1%;
  font-size: 80%
}
&lt;/style&gt;





---
count: false
 
# Combining strings
.panel1-combiningstrings-rotate[

```r
age &lt;- seq(from = 12, to = 24, by = .5)
*paste0("data_raw/vocab", age, ".csv")
```
]
 
.panel2-combiningstrings-rotate[

```
 [1] "data_raw/vocab12.csv"   "data_raw/vocab12.5.csv" "data_raw/vocab13.csv"  
 [4] "data_raw/vocab13.5.csv" "data_raw/vocab14.csv"   "data_raw/vocab14.5.csv"
 [7] "data_raw/vocab15.csv"   "data_raw/vocab15.5.csv" "data_raw/vocab16.csv"  
[10] "data_raw/vocab16.5.csv" "data_raw/vocab17.csv"   "data_raw/vocab17.5.csv"
[13] "data_raw/vocab18.csv"   "data_raw/vocab18.5.csv" "data_raw/vocab19.csv"  
[16] "data_raw/vocab19.5.csv" "data_raw/vocab20.csv"   "data_raw/vocab20.5.csv"
[19] "data_raw/vocab21.csv"   "data_raw/vocab21.5.csv" "data_raw/vocab22.csv"  
[22] "data_raw/vocab22.5.csv" "data_raw/vocab23.csv"   "data_raw/vocab23.5.csv"
[25] "data_raw/vocab24.csv"  
```
]

---
count: false
 
# Combining strings
.panel1-combiningstrings-rotate[

```r
age &lt;- seq(from = 12, to = 24, by = .5)
*str_glue("data_raw/vocab{age}.csv")
```
]
 
.panel2-combiningstrings-rotate[

```
data_raw/vocab12.csv
data_raw/vocab12.5.csv
data_raw/vocab13.csv
data_raw/vocab13.5.csv
data_raw/vocab14.csv
data_raw/vocab14.5.csv
data_raw/vocab15.csv
data_raw/vocab15.5.csv
data_raw/vocab16.csv
data_raw/vocab16.5.csv
data_raw/vocab17.csv
data_raw/vocab17.5.csv
data_raw/vocab18.csv
data_raw/vocab18.5.csv
data_raw/vocab19.csv
data_raw/vocab19.5.csv
data_raw/vocab20.csv
data_raw/vocab20.5.csv
data_raw/vocab21.csv
data_raw/vocab21.5.csv
data_raw/vocab22.csv
data_raw/vocab22.5.csv
data_raw/vocab23.csv
data_raw/vocab23.5.csv
data_raw/vocab24.csv
```
]

---
count: false
 
# Combining strings
.panel1-combiningstrings-rotate[

```r
age &lt;- seq(from = 12, to = 24, by = .5)
*str_glue("Today's date and time are {now()}")
```
]
 
.panel2-combiningstrings-rotate[

```
Today's date and time are 2022-01-31 12:52:45
```
]

---
count: false
 
# Combining strings
.panel1-combiningstrings-rotate[

```r
age &lt;- seq(from = 12, to = 24, by = .5)
*str_glue("Here is pi to {x} digits: {format(pi, digits = x)}", x = 3)
```
]
 
.panel2-combiningstrings-rotate[

```
Here is pi to 3 digits: 3.14
```
]

---
count: false
 
# Combining strings
.panel1-combiningstrings-rotate[

```r
age &lt;- seq(from = 12, to = 24, by = .5)
*str_glue("Here is pi to {x} digits: {format(pi, digits = x)}", x = 4)
```
]
 
.panel2-combiningstrings-rotate[

```
Here is pi to 4 digits: 3.142
```
]

---
count: false
 
# Combining strings
.panel1-combiningstrings-rotate[

```r
age &lt;- seq(from = 12, to = 24, by = .5)
*str_glue("Here is pi to {x} digits: {format(pi, digits = x)}", x = 5)
```
]
 
.panel2-combiningstrings-rotate[

```
Here is pi to 5 digits: 3.1416
```
]

---
count: false
 
# Combining strings
.panel1-combiningstrings-rotate[

```r
age &lt;- seq(from = 12, to = 24, by = .5)
*str_glue("Here is pi to {x} digits: {format(pi, digits = x)}", x = 6)
```
]
 
.panel2-combiningstrings-rotate[

```
Here is pi to 6 digits: 3.14159
```
]

&lt;style&gt;
.panel1-combiningstrings-rotate {
  color: black;
  width: 90.4615384615385%;
  hight: 32%;
  float: none;
  padding-left: 1%;
  font-size: 80%
}
.panel2-combiningstrings-rotate {
  color: black;
  width: 7.53846153846154%;
  hight: 32%;
  float: none;
  padding-left: 1%;
  font-size: 80%
}
.panel3-combiningstrings-rotate {
  color: black;
  width: NA%;
  hight: 33%;
  float: none;
  padding-left: 1%;
  font-size: 80%
}
&lt;/style&gt;



---
# Working with dates and times
- Correctly parse dates/times from character data

- Calculate differences between dates/times (e.g., ages, task length)

- Determine local time using time zones

- Lots of options within the `lubridate` package



---
count: false
 
# Parsing dates
.panel1-parse-rotate[

```r
dates  # ROTATE
*dates %&gt;% mutate(dates1_parsed = ymd(dates1))
```
]
 
.panel2-parse-rotate[

```
# A tibble: 4 × 3
  dates1     dates2     dates3          
  &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;           
1 2017-09-01 9/01/2018  March 1, 2019   
2 2016-09-01 09/01/2017 May 1, 2018     
3 2015-09-01 9/1/2016   January 20, 2017
4 2014-09-01 9/1/2015   February 4, 2020
```

```
# A tibble: 4 × 4
  dates1     dates2     dates3           dates1_parsed
  &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;            &lt;date&gt;       
1 2017-09-01 9/01/2018  March 1, 2019    2017-09-01   
2 2016-09-01 09/01/2017 May 1, 2018      2016-09-01   
3 2015-09-01 9/1/2016   January 20, 2017 2015-09-01   
4 2014-09-01 9/1/2015   February 4, 2020 2014-09-01   
```
]

---
count: false
 
# Parsing dates
.panel1-parse-rotate[

```r
dates  # ROTATE
*dates %&gt;% mutate(dates2_parsed = mdy(dates2))
```
]
 
.panel2-parse-rotate[

```
# A tibble: 4 × 3
  dates1     dates2     dates3          
  &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;           
1 2017-09-01 9/01/2018  March 1, 2019   
2 2016-09-01 09/01/2017 May 1, 2018     
3 2015-09-01 9/1/2016   January 20, 2017
4 2014-09-01 9/1/2015   February 4, 2020
```

```
# A tibble: 4 × 4
  dates1     dates2     dates3           dates2_parsed
  &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;            &lt;date&gt;       
1 2017-09-01 9/01/2018  March 1, 2019    2018-09-01   
2 2016-09-01 09/01/2017 May 1, 2018      2017-09-01   
3 2015-09-01 9/1/2016   January 20, 2017 2016-09-01   
4 2014-09-01 9/1/2015   February 4, 2020 2015-09-01   
```
]

---
count: false
 
# Parsing dates
.panel1-parse-rotate[

```r
dates  # ROTATE
*dates %&gt;% mutate(dates3_parsed = parse_date(dates3, format = "%B %d, %Y"))
```
]
 
.panel2-parse-rotate[

```
# A tibble: 4 × 3
  dates1     dates2     dates3          
  &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;           
1 2017-09-01 9/01/2018  March 1, 2019   
2 2016-09-01 09/01/2017 May 1, 2018     
3 2015-09-01 9/1/2016   January 20, 2017
4 2014-09-01 9/1/2015   February 4, 2020
```

```
# A tibble: 4 × 4
  dates1     dates2     dates3           dates3_parsed
  &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;            &lt;date&gt;       
1 2017-09-01 9/01/2018  March 1, 2019    2019-03-01   
2 2016-09-01 09/01/2017 May 1, 2018      2018-05-01   
3 2015-09-01 9/1/2016   January 20, 2017 2017-01-20   
4 2014-09-01 9/1/2015   February 4, 2020 2020-02-04   
```
]

&lt;style&gt;
.panel1-parse-rotate {
  color: black;
  width: 90.4615384615385%;
  hight: 32%;
  float: none;
  padding-left: 1%;
  font-size: 80%
}
.panel2-parse-rotate {
  color: black;
  width: 7.53846153846154%;
  hight: 32%;
  float: none;
  padding-left: 1%;
  font-size: 80%
}
.panel3-parse-rotate {
  color: black;
  width: NA%;
  hight: 33%;
  float: none;
  padding-left: 1%;
  font-size: 80%
}
&lt;/style&gt;





---
# Time is weird

- Leap days and leap seconds mean that physical time is not the same as calendar time
  * lubridate `durations` represent physical time
  * lubridate `periods` represent the passage of calendar time


```r
time_length(mdy("05-27-2022")-mdy("05-27-1983"), "years")
```

```
[1] 39.00068
```

```r
time_length(as.period(interval(mdy("05-27-1983"), mdy("05-27-2022"))), "years")
```

```
[1] 39
```

```r
time_length(as.period(interval(mdy("05-27-1983"), mdy("05-28-2022"))), "years")
```

```
[1] 39.00274
```

---
count: false
 
# Age math
.panel1-age-auto[

```r
*birth_date &lt;- ymd("2001-09-01", "2000-09-01")
```
]
 
.panel2-age-auto[

]

---
count: false
 
# Age math
.panel1-age-auto[

```r
birth_date &lt;- ymd("2001-09-01", "2000-09-01")
*test_date &lt;- ymd("2020-09-01", "2019-09-01")
```
]
 
.panel2-age-auto[

]

---
count: false
 
# Age math
.panel1-age-auto[

```r
birth_date &lt;- ymd("2001-09-01", "2000-09-01")
test_date &lt;- ymd("2020-09-01", "2019-09-01")
*(test_date-birth_date)/365.25
```
]
 
.panel2-age-auto[

```
Time differences in days
[1] 19.00068 18.99795
```
]

---
count: false
 
# Age math
.panel1-age-auto[

```r
birth_date &lt;- ymd("2001-09-01", "2000-09-01")
test_date &lt;- ymd("2020-09-01", "2019-09-01")
(test_date-birth_date)/365.25
*as.period(interval(start = birth_date, end = test_date), unit = "years")
```
]
 
.panel2-age-auto[

```
Time differences in days
[1] 19.00068 18.99795
```

```
[1] "19y 0m 0d 0H 0M 0S" "19y 0m 0d 0H 0M 0S"
```
]

---
count: false
 
# Age math
.panel1-age-auto[

```r
birth_date &lt;- ymd("2001-09-01", "2000-09-01")
test_date &lt;- ymd("2020-09-01", "2019-09-01")
(test_date-birth_date)/365.25
as.period(interval(start = birth_date, end = test_date), unit = "years")
*test_date - years(1) + days(7)
```
]
 
.panel2-age-auto[

```
Time differences in days
[1] 19.00068 18.99795
```

```
[1] "19y 0m 0d 0H 0M 0S" "19y 0m 0d 0H 0M 0S"
```

```
[1] "2019-09-08" "2018-09-08"
```
]

&lt;style&gt;
.panel1-age-auto {
  color: black;
  width: 90.4615384615385%;
  hight: 32%;
  float: none;
  padding-left: 1%;
  font-size: 80%
}
.panel2-age-auto {
  color: black;
  width: 7.53846153846154%;
  hight: 32%;
  float: none;
  padding-left: 1%;
  font-size: 80%
}
.panel3-age-auto {
  color: black;
  width: NA%;
  hight: 33%;
  float: none;
  padding-left: 1%;
  font-size: 80%
}
&lt;/style&gt;




---
count: false
 
# Time Zones
.panel1-tz-auto[

```r
*t1 &lt;- as_datetime("2022-01-27 10:39:28", tz = "America/Los_Angeles")
```
]
 
.panel2-tz-auto[

]

---
count: false
 
# Time Zones
.panel1-tz-auto[

```r
t1 &lt;- as_datetime("2022-01-27 10:39:28", tz = "America/Los_Angeles")
*t1
```
]
 
.panel2-tz-auto[

```
[1] "2022-01-27 10:39:28 PST"
```
]

---
count: false
 
# Time Zones
.panel1-tz-auto[

```r
t1 &lt;- as_datetime("2022-01-27 10:39:28", tz = "America/Los_Angeles")
t1
*tz(t1)
```
]
 
.panel2-tz-auto[

```
[1] "2022-01-27 10:39:28 PST"
```

```
[1] "America/Los_Angeles"
```
]

---
count: false
 
# Time Zones
.panel1-tz-auto[

```r
t1 &lt;- as_datetime("2022-01-27 10:39:28", tz = "America/Los_Angeles")
t1
tz(t1)
*t2 &lt;- as_datetime("2022-01-27 13:39:28", tz = "America/New_York")
```
]
 
.panel2-tz-auto[

```
[1] "2022-01-27 10:39:28 PST"
```

```
[1] "America/Los_Angeles"
```
]

---
count: false
 
# Time Zones
.panel1-tz-auto[

```r
t1 &lt;- as_datetime("2022-01-27 10:39:28", tz = "America/Los_Angeles")
t1
tz(t1)
t2 &lt;- as_datetime("2022-01-27 13:39:28", tz = "America/New_York")
*t2-t1
```
]
 
.panel2-tz-auto[

```
[1] "2022-01-27 10:39:28 PST"
```

```
[1] "America/Los_Angeles"
```

```
Time difference of 0 secs
```
]

---
count: false
 
# Time Zones
.panel1-tz-auto[

```r
t1 &lt;- as_datetime("2022-01-27 10:39:28", tz = "America/Los_Angeles")
t1
tz(t1)
t2 &lt;- as_datetime("2022-01-27 13:39:28", tz = "America/New_York")
t2-t1
*t3 &lt;- as_datetime("2021-10-15 10:39:28", tz = "America/Los_Angeles")
```
]
 
.panel2-tz-auto[

```
[1] "2022-01-27 10:39:28 PST"
```

```
[1] "America/Los_Angeles"
```

```
Time difference of 0 secs
```
]

---
count: false
 
# Time Zones
.panel1-tz-auto[

```r
t1 &lt;- as_datetime("2022-01-27 10:39:28", tz = "America/Los_Angeles")
t1
tz(t1)
t2 &lt;- as_datetime("2022-01-27 13:39:28", tz = "America/New_York")
t2-t1
t3 &lt;- as_datetime("2021-10-15 10:39:28", tz = "America/Los_Angeles")
*t3
```
]
 
.panel2-tz-auto[

```
[1] "2022-01-27 10:39:28 PST"
```

```
[1] "America/Los_Angeles"
```

```
Time difference of 0 secs
```

```
[1] "2021-10-15 10:39:28 PDT"
```
]

---
count: false
 
# Time Zones
.panel1-tz-auto[

```r
t1 &lt;- as_datetime("2022-01-27 10:39:28", tz = "America/Los_Angeles")
t1
tz(t1)
t2 &lt;- as_datetime("2022-01-27 13:39:28", tz = "America/New_York")
t2-t1
t3 &lt;- as_datetime("2021-10-15 10:39:28", tz = "America/Los_Angeles")
t3
*as.period(interval(start = t3, end = t1), unit = "days")
```
]
 
.panel2-tz-auto[

```
[1] "2022-01-27 10:39:28 PST"
```

```
[1] "America/Los_Angeles"
```

```
Time difference of 0 secs
```

```
[1] "2021-10-15 10:39:28 PDT"
```

```
[1] "104d 1H 0M 0S"
```
]

---
count: false
 
# Time Zones
.panel1-tz-auto[

```r
t1 &lt;- as_datetime("2022-01-27 10:39:28", tz = "America/Los_Angeles")
t1
tz(t1)
t2 &lt;- as_datetime("2022-01-27 13:39:28", tz = "America/New_York")
t2-t1
t3 &lt;- as_datetime("2021-10-15 10:39:28", tz = "America/Los_Angeles")
t3
as.period(interval(start = t3, end = t1), unit = "days")
*with_tz(t3, "America/New_York")
```
]
 
.panel2-tz-auto[

```
[1] "2022-01-27 10:39:28 PST"
```

```
[1] "America/Los_Angeles"
```

```
Time difference of 0 secs
```

```
[1] "2021-10-15 10:39:28 PDT"
```

```
[1] "104d 1H 0M 0S"
```

```
[1] "2021-10-15 13:39:28 EDT"
```
]

---
count: false
 
# Time Zones
.panel1-tz-auto[

```r
t1 &lt;- as_datetime("2022-01-27 10:39:28", tz = "America/Los_Angeles")
t1
tz(t1)
t2 &lt;- as_datetime("2022-01-27 13:39:28", tz = "America/New_York")
t2-t1
t3 &lt;- as_datetime("2021-10-15 10:39:28", tz = "America/Los_Angeles")
t3
as.period(interval(start = t3, end = t1), unit = "days")
with_tz(t3, "America/New_York")
*force_tz(t3, "America/New_York")
```
]
 
.panel2-tz-auto[

```
[1] "2022-01-27 10:39:28 PST"
```

```
[1] "America/Los_Angeles"
```

```
Time difference of 0 secs
```

```
[1] "2021-10-15 10:39:28 PDT"
```

```
[1] "104d 1H 0M 0S"
```

```
[1] "2021-10-15 13:39:28 EDT"
```

```
[1] "2021-10-15 10:39:28 EDT"
```
]

&lt;style&gt;
.panel1-tz-auto {
  color: black;
  width: 65.3333333333333%;
  hight: 32%;
  float: left;
  padding-left: 1%;
  font-size: 80%
}
.panel2-tz-auto {
  color: black;
  width: 32.6666666666667%;
  hight: 32%;
  float: left;
  padding-left: 1%;
  font-size: 80%
}
.panel3-tz-auto {
  color: black;
  width: NA%;
  hight: 33%;
  float: left;
  padding-left: 1%;
  font-size: 80%
}
&lt;/style&gt;





---
# Factors represent categories

```r
x &lt;- c(1, 1, 2, 3, 1, 4)
x &lt;- factor(x, levels = c(1,2,3), labels = c("rarely", "neutral", "frequently"))
x
```

```
[1] rarely     rarely     neutral    frequently rarely     &lt;NA&gt;      
Levels: rarely neutral frequently
```
- levels restrict the possible set of values

- levels are ordered, which carries forward to output, modeling, graphics, etc.

- factors work as dummy codes; use as.numeric(factor) to treat as a continuous variable in models

---
count: false
 
# Factors
.panel1-factors-auto[

```r
*ds &lt;- starwars
```
]
 
.panel2-factors-auto[

]

---
count: false
 
# Factors
.panel1-factors-auto[

```r
ds &lt;- starwars
*unique(ds$eye_color)
```
]
 
.panel2-factors-auto[

```
 [1] "blue"          "yellow"        "red"           "brown"        
 [5] "blue-gray"     "black"         "orange"        "hazel"        
 [9] "pink"          "unknown"       "red, blue"     "gold"         
[13] "green, yellow" "white"         "dark"         
```
]

---
count: false
 
# Factors
.panel1-factors-auto[

```r
ds &lt;- starwars
unique(ds$eye_color)
*ds &lt;- ds %&gt;% mutate(eye_f = factor(eye_color))
```
]
 
.panel2-factors-auto[

```
 [1] "blue"          "yellow"        "red"           "brown"        
 [5] "blue-gray"     "black"         "orange"        "hazel"        
 [9] "pink"          "unknown"       "red, blue"     "gold"         
[13] "green, yellow" "white"         "dark"         
```
]

---
count: false
 
# Factors
.panel1-factors-auto[

```r
ds &lt;- starwars
unique(ds$eye_color)
ds &lt;- ds %&gt;% mutate(eye_f = factor(eye_color))
*fct_count(ds$eye_f, sort = T) %&gt;% slice_head(n = 5)
```
]
 
.panel2-factors-auto[

```
 [1] "blue"          "yellow"        "red"           "brown"        
 [5] "blue-gray"     "black"         "orange"        "hazel"        
 [9] "pink"          "unknown"       "red, blue"     "gold"         
[13] "green, yellow" "white"         "dark"         
```

```
# A tibble: 5 × 2
  f          n
  &lt;fct&gt;  &lt;int&gt;
1 brown     21
2 blue      19
3 yellow    11
4 black     10
5 orange     8
```
]

---
count: false
 
# Factors
.panel1-factors-auto[

```r
ds &lt;- starwars
unique(ds$eye_color)
ds &lt;- ds %&gt;% mutate(eye_f = factor(eye_color))
fct_count(ds$eye_f, sort = T) %&gt;% slice_head(n = 5)
*fct_count(ds$eye_f, prop = T) %&gt;% slice_head(n = 5)
```
]
 
.panel2-factors-auto[

```
 [1] "blue"          "yellow"        "red"           "brown"        
 [5] "blue-gray"     "black"         "orange"        "hazel"        
 [9] "pink"          "unknown"       "red, blue"     "gold"         
[13] "green, yellow" "white"         "dark"         
```

```
# A tibble: 5 × 2
  f          n
  &lt;fct&gt;  &lt;int&gt;
1 brown     21
2 blue      19
3 yellow    11
4 black     10
5 orange     8
```

```
# A tibble: 5 × 3
  f             n      p
  &lt;fct&gt;     &lt;int&gt;  &lt;dbl&gt;
1 black        10 0.115 
2 blue         19 0.218 
3 blue-gray     1 0.0115
4 brown        21 0.241 
5 dark          1 0.0115
```
]

&lt;style&gt;
.panel1-factors-auto {
  color: black;
  width: 49%;
  hight: 32%;
  float: left;
  padding-left: 1%;
  font-size: 80%
}
.panel2-factors-auto {
  color: black;
  width: 49%;
  hight: 32%;
  float: left;
  padding-left: 1%;
  font-size: 80%
}
.panel3-factors-auto {
  color: black;
  width: NA%;
  hight: 33%;
  float: left;
  padding-left: 1%;
  font-size: 80%
}
&lt;/style&gt;





---
count: false
 
# Setting factor levels
.panel1-releveling-rotate[

```r
ds &lt;- ds %&gt;% select(name, eye_f)
*ds
```
]
 
.panel2-releveling-rotate[

```
# A tibble: 87 × 2
   name               eye_f    
   &lt;chr&gt;              &lt;fct&gt;    
 1 Luke Skywalker     blue     
 2 C-3PO              yellow   
 3 R2-D2              red      
 4 Darth Vader        yellow   
 5 Leia Organa        brown    
 6 Owen Lars          blue     
 7 Beru Whitesun lars blue     
 8 R5-D4              red      
 9 Biggs Darklighter  brown    
10 Obi-Wan Kenobi     blue-gray
# … with 77 more rows
```
]

---
count: false
 
# Setting factor levels
.panel1-releveling-rotate[

```r
ds &lt;- ds %&gt;% select(name, eye_f)
*ds %&gt;% mutate(eye_f2 = factor(eye_f, levels = c("blue", "brown")))
```
]
 
.panel2-releveling-rotate[

```
# A tibble: 87 × 3
   name               eye_f     eye_f2
   &lt;chr&gt;              &lt;fct&gt;     &lt;fct&gt; 
 1 Luke Skywalker     blue      blue  
 2 C-3PO              yellow    &lt;NA&gt;  
 3 R2-D2              red       &lt;NA&gt;  
 4 Darth Vader        yellow    &lt;NA&gt;  
 5 Leia Organa        brown     brown 
 6 Owen Lars          blue      blue  
 7 Beru Whitesun lars blue      blue  
 8 R5-D4              red       &lt;NA&gt;  
 9 Biggs Darklighter  brown     brown 
10 Obi-Wan Kenobi     blue-gray &lt;NA&gt;  
# … with 77 more rows
```
]

---
count: false
 
# Setting factor levels
.panel1-releveling-rotate[

```r
ds &lt;- ds %&gt;% select(name, eye_f)
*ds %&gt;% mutate(eye_f2 = factor(eye_f, levels = c("blue", "brown"), labels = c("bl","br")))
```
]
 
.panel2-releveling-rotate[

```
# A tibble: 87 × 3
   name               eye_f     eye_f2
   &lt;chr&gt;              &lt;fct&gt;     &lt;fct&gt; 
 1 Luke Skywalker     blue      bl    
 2 C-3PO              yellow    &lt;NA&gt;  
 3 R2-D2              red       &lt;NA&gt;  
 4 Darth Vader        yellow    &lt;NA&gt;  
 5 Leia Organa        brown     br    
 6 Owen Lars          blue      bl    
 7 Beru Whitesun lars blue      bl    
 8 R5-D4              red       &lt;NA&gt;  
 9 Biggs Darklighter  brown     br    
10 Obi-Wan Kenobi     blue-gray &lt;NA&gt;  
# … with 77 more rows
```
]

---
count: false
 
# Setting factor levels
.panel1-releveling-rotate[

```r
ds &lt;- ds %&gt;% select(name, eye_f)
*ds %&gt;% mutate(eye_f2 = fct_lump(eye_f, n = 3))
```
]
 
.panel2-releveling-rotate[

```
# A tibble: 87 × 3
   name               eye_f     eye_f2
   &lt;chr&gt;              &lt;fct&gt;     &lt;fct&gt; 
 1 Luke Skywalker     blue      blue  
 2 C-3PO              yellow    yellow
 3 R2-D2              red       Other 
 4 Darth Vader        yellow    yellow
 5 Leia Organa        brown     brown 
 6 Owen Lars          blue      blue  
 7 Beru Whitesun lars blue      blue  
 8 R5-D4              red       Other 
 9 Biggs Darklighter  brown     brown 
10 Obi-Wan Kenobi     blue-gray Other 
# … with 77 more rows
```
]

---
count: false
 
# Setting factor levels
.panel1-releveling-rotate[

```r
ds &lt;- ds %&gt;% select(name, eye_f)
*ds %&gt;% mutate(eye_type = fct_collapse(eye_f, human = c("blue", "brown"), nonhuman = c("yellow", "red")))
```
]
 
.panel2-releveling-rotate[

```
# A tibble: 87 × 3
   name               eye_f     eye_type 
   &lt;chr&gt;              &lt;fct&gt;     &lt;fct&gt;    
 1 Luke Skywalker     blue      human    
 2 C-3PO              yellow    nonhuman 
 3 R2-D2              red       nonhuman 
 4 Darth Vader        yellow    nonhuman 
 5 Leia Organa        brown     human    
 6 Owen Lars          blue      human    
 7 Beru Whitesun lars blue      human    
 8 R5-D4              red       nonhuman 
 9 Biggs Darklighter  brown     human    
10 Obi-Wan Kenobi     blue-gray blue-gray
# … with 77 more rows
```
]

&lt;style&gt;
.panel1-releveling-rotate {
  color: black;
  width: 87.1111111111111%;
  hight: 32%;
  float: none;
  padding-left: 1%;
  font-size: 80%
}
.panel2-releveling-rotate {
  color: black;
  width: 10.8888888888889%;
  hight: 32%;
  float: none;
  padding-left: 1%;
  font-size: 80%
}
.panel3-releveling-rotate {
  color: black;
  width: NA%;
  hight: 33%;
  float: none;
  padding-left: 1%;
  font-size: 80%
}
&lt;/style&gt;





---
count: false
 
# Reordering factor levels
.panel1-reordering-rotate[

```r
*fct_count(ds$eye_f)
```
]
 
.panel2-reordering-rotate[

```
# A tibble: 15 × 2
   f                 n
   &lt;fct&gt;         &lt;int&gt;
 1 black            10
 2 blue             19
 3 blue-gray         1
 4 brown            21
 5 dark              1
 6 gold              1
 7 green, yellow     1
 8 hazel             3
 9 orange            8
10 pink              1
11 red               5
12 red, blue         1
13 unknown           3
14 white             1
15 yellow           11
```
]

---
count: false
 
# Reordering factor levels
.panel1-reordering-rotate[

```r
*fct_count(fct_rev(ds$eye_f))
```
]
 
.panel2-reordering-rotate[

```
# A tibble: 15 × 2
   f                 n
   &lt;fct&gt;         &lt;int&gt;
 1 yellow           11
 2 white             1
 3 unknown           3
 4 red, blue         1
 5 red               5
 6 pink              1
 7 orange            8
 8 hazel             3
 9 green, yellow     1
10 gold              1
11 dark              1
12 brown            21
13 blue-gray         1
14 blue             19
15 black            10
```
]

---
count: false
 
# Reordering factor levels
.panel1-reordering-rotate[

```r
*fct_count(fct_infreq(ds$eye_f))
```
]
 
.panel2-reordering-rotate[

```
# A tibble: 15 × 2
   f                 n
   &lt;fct&gt;         &lt;int&gt;
 1 brown            21
 2 blue             19
 3 yellow           11
 4 black            10
 5 orange            8
 6 red               5
 7 hazel             3
 8 unknown           3
 9 blue-gray         1
10 dark              1
11 gold              1
12 green, yellow     1
13 pink              1
14 red, blue         1
15 white             1
```
]

---
count: false
 
# Reordering factor levels
.panel1-reordering-rotate[

```r
*fct_count(factor(ds$eye_f, levels = c("red", "brown", "blue")))
```
]
 
.panel2-reordering-rotate[

```
# A tibble: 4 × 2
  f         n
  &lt;fct&gt; &lt;int&gt;
1 red       5
2 brown    21
3 blue     19
4 &lt;NA&gt;     42
```
]

&lt;style&gt;
.panel1-reordering-rotate {
  color: black;
  width: 87.1111111111111%;
  hight: 32%;
  float: none;
  padding-left: 1%;
  font-size: 80%
}
.panel2-reordering-rotate {
  color: black;
  width: 10.8888888888889%;
  hight: 32%;
  float: none;
  padding-left: 1%;
  font-size: 80%
}
.panel3-reordering-rotate {
  color: black;
  width: NA%;
  hight: 33%;
  float: none;
  padding-left: 1%;
  font-size: 80%
}
&lt;/style&gt;





---
#Tidy data (Wickham, 2014)

- Each variable is a column
  * A variable means "all values that measure the same underlying attribute"
- Each observation is a row
  * Observation means unit for which all variables are measured (e.g., person, session, trial)
- Each type of observational unit is a separate table
  * Participant questionnaire vs. trial-by-trial outcomes

---
#Why do data need to be tidied?

- Data files are often created without the foresight of how they will be read by computers
- Creators prioritize making things human-readable at the expense of making data machine-readable
- Tidy data makes programming more convenient
  * Analysis and graphing functions in R (e.g., lm, lmer, ggplot) expect data in long format
- You may need to switch formats to fit data to different requirements or to output data for publication (tables)

---
#Types of un-tidy data: Column names are variables
- Income level can’t be made a factor to use in a model
- Challenging to summarize, each income level needs to be treated as a separate variable
- Can't use filter to subset each kind of observation

```r
relig_income %&gt;% slice_head(n = 5)
```

```
# A tibble: 5 × 11
  religion  `&lt;$10k` `$10-20k` `$20-30k` `$30-40k` `$40-50k` `$50-75k` `$75-100k`
  &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;
1 Agnostic       27        34        60        81        76       137        122
2 Atheist        12        27        37        52        35        70         73
3 Buddhist       27        21        30        34        33        58         62
4 Catholic      418       617       732       670       638      1116        949
5 Don’t kn…      15        14        15        11        10        35         21
# … with 3 more variables: $100-150k &lt;dbl&gt;, &gt;150k &lt;dbl&gt;,
#   Don't know/refused &lt;dbl&gt;
```

---
#Solution: tidyr's pivot_longer() function


```r
relig_income %&gt;% 
  pivot_longer(cols = -religion, names_to = "income", values_to = "count")
```

```
# A tibble: 180 × 3
   religion income             count
   &lt;chr&gt;    &lt;chr&gt;              &lt;dbl&gt;
 1 Agnostic &lt;$10k                 27
 2 Agnostic $10-20k               34
 3 Agnostic $20-30k               60
 4 Agnostic $30-40k               81
 5 Agnostic $40-50k               76
 6 Agnostic $50-75k              137
 7 Agnostic $75-100k             122
 8 Agnostic $100-150k            109
 9 Agnostic &gt;150k                 84
10 Agnostic Don't know/refused    96
# … with 170 more rows
```

---
count: false
 

.panel1-pivotlong-rotate[

```r
ds &lt;- read_csv('data_cleaned/vocab_annoying_headers.csv') %&gt;%
  mutate(id = "Jonah", dob = as.Date("2017-08-30"), .before = "age_12")
*ds %&gt;% print(n = 25)
```
]
 
.panel2-pivotlong-rotate[

```
# A tibble: 51 × 27
   id    dob        age_12  age_12.5 age_13 age_13.5 age_14 age_14.5     age_15
   &lt;chr&gt; &lt;date&gt;     &lt;chr&gt;   &lt;chr&gt;    &lt;lgl&gt;  &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;        &lt;chr&gt; 
 1 Jonah 2017-08-30 book    dad      NA     cat      baby   socks/shoes  banana
 2 Jonah 2017-08-30 ball    &lt;NA&gt;     NA     &lt;NA&gt;     &lt;NA&gt;   dog (animal) llama 
 3 Jonah 2017-08-30 bye bye &lt;NA&gt;     NA     &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;  
 4 Jonah 2017-08-30 &lt;NA&gt;    &lt;NA&gt;     NA     &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;  
 5 Jonah 2017-08-30 &lt;NA&gt;    &lt;NA&gt;     NA     &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;  
 6 Jonah 2017-08-30 &lt;NA&gt;    &lt;NA&gt;     NA     &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;  
 7 Jonah 2017-08-30 &lt;NA&gt;    &lt;NA&gt;     NA     &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;  
 8 Jonah 2017-08-30 &lt;NA&gt;    &lt;NA&gt;     NA     &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;  
 9 Jonah 2017-08-30 &lt;NA&gt;    &lt;NA&gt;     NA     &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;  
10 Jonah 2017-08-30 &lt;NA&gt;    &lt;NA&gt;     NA     &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;  
11 Jonah 2017-08-30 &lt;NA&gt;    &lt;NA&gt;     NA     &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;  
12 Jonah 2017-08-30 &lt;NA&gt;    &lt;NA&gt;     NA     &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;  
13 Jonah 2017-08-30 &lt;NA&gt;    &lt;NA&gt;     NA     &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;  
14 Jonah 2017-08-30 &lt;NA&gt;    &lt;NA&gt;     NA     &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;  
15 Jonah 2017-08-30 &lt;NA&gt;    &lt;NA&gt;     NA     &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;  
16 Jonah 2017-08-30 &lt;NA&gt;    &lt;NA&gt;     NA     &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;  
17 Jonah 2017-08-30 &lt;NA&gt;    &lt;NA&gt;     NA     &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;  
18 Jonah 2017-08-30 &lt;NA&gt;    &lt;NA&gt;     NA     &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;  
19 Jonah 2017-08-30 &lt;NA&gt;    &lt;NA&gt;     NA     &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;  
20 Jonah 2017-08-30 &lt;NA&gt;    &lt;NA&gt;     NA     &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;  
21 Jonah 2017-08-30 &lt;NA&gt;    &lt;NA&gt;     NA     &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;  
22 Jonah 2017-08-30 &lt;NA&gt;    &lt;NA&gt;     NA     &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;  
23 Jonah 2017-08-30 &lt;NA&gt;    &lt;NA&gt;     NA     &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;  
24 Jonah 2017-08-30 &lt;NA&gt;    &lt;NA&gt;     NA     &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;  
25 Jonah 2017-08-30 &lt;NA&gt;    &lt;NA&gt;     NA     &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;  
# … with 26 more rows, and 18 more variables: age_15.5 &lt;chr&gt;, age_16 &lt;chr&gt;,
#   age_16.5 &lt;chr&gt;, age_17 &lt;chr&gt;, age_17.5 &lt;chr&gt;, age_18 &lt;chr&gt;, age_18.5 &lt;chr&gt;,
#   age_19 &lt;chr&gt;, age_19.5 &lt;chr&gt;, age_20 &lt;chr&gt;, age_20.5 &lt;chr&gt;, age_21 &lt;chr&gt;,
#   age_21.5 &lt;chr&gt;, age_22 &lt;chr&gt;, age_22.5 &lt;chr&gt;, age_23 &lt;chr&gt;, age_23.5 &lt;chr&gt;,
#   age_24 &lt;chr&gt;
```
]

---
count: false
 

.panel1-pivotlong-rotate[

```r
ds &lt;- read_csv('data_cleaned/vocab_annoying_headers.csv') %&gt;%
  mutate(id = "Jonah", dob = as.Date("2017-08-30"), .before = "age_12")
*ds %&gt;% pivot_longer(-(id:dob), names_to = "age", values_to = "word") %&gt;% print(n = 65)
```
]
 
.panel2-pivotlong-rotate[

```
# A tibble: 1,275 × 4
   id    dob        age      word         
   &lt;chr&gt; &lt;date&gt;     &lt;chr&gt;    &lt;chr&gt;        
 1 Jonah 2017-08-30 age_12   book         
 2 Jonah 2017-08-30 age_12.5 dad          
 3 Jonah 2017-08-30 age_13   &lt;NA&gt;         
 4 Jonah 2017-08-30 age_13.5 cat          
 5 Jonah 2017-08-30 age_14   baby         
 6 Jonah 2017-08-30 age_14.5 socks/shoes  
 7 Jonah 2017-08-30 age_15   banana       
 8 Jonah 2017-08-30 age_15.5 cheese       
 9 Jonah 2017-08-30 age_16   shoes        
10 Jonah 2017-08-30 age_16.5 monkey       
11 Jonah 2017-08-30 age_17   hello        
12 Jonah 2017-08-30 age_17.5 bear         
13 Jonah 2017-08-30 age_18   milk/drink   
14 Jonah 2017-08-30 age_18.5 cleanup      
15 Jonah 2017-08-30 age_19   grandpa      
16 Jonah 2017-08-30 age_19.5 mouth        
17 Jonah 2017-08-30 age_20   coffee       
18 Jonah 2017-08-30 age_20.5 agua         
19 Jonah 2017-08-30 age_21   octopus      
20 Jonah 2017-08-30 age_21.5 (wrist) watch
21 Jonah 2017-08-30 age_22   shower       
22 Jonah 2017-08-30 age_22.5 hyena        
23 Jonah 2017-08-30 age_23   heart        
24 Jonah 2017-08-30 age_23.5 singing      
25 Jonah 2017-08-30 age_24   top          
26 Jonah 2017-08-30 age_12   ball         
27 Jonah 2017-08-30 age_12.5 &lt;NA&gt;         
28 Jonah 2017-08-30 age_13   &lt;NA&gt;         
29 Jonah 2017-08-30 age_13.5 &lt;NA&gt;         
30 Jonah 2017-08-30 age_14   &lt;NA&gt;         
31 Jonah 2017-08-30 age_14.5 dog (animal) 
32 Jonah 2017-08-30 age_15   llama        
33 Jonah 2017-08-30 age_15.5 turkey       
34 Jonah 2017-08-30 age_16   berry        
35 Jonah 2017-08-30 age_16.5 apple        
36 Jonah 2017-08-30 age_17   oh no        
37 Jonah 2017-08-30 age_17.5 go           
38 Jonah 2017-08-30 age_18   car          
39 Jonah 2017-08-30 age_18.5 that         
40 Jonah 2017-08-30 age_19   more         
41 Jonah 2017-08-30 age_19.5 peacock      
42 Jonah 2017-08-30 age_20   cup          
43 Jonah 2017-08-30 age_20.5 hide         
44 Jonah 2017-08-30 age_21   too          
45 Jonah 2017-08-30 age_21.5 blanket      
46 Jonah 2017-08-30 age_22   peanut butter
47 Jonah 2017-08-30 age_22.5 running      
48 Jonah 2017-08-30 age_23   empty        
49 Jonah 2017-08-30 age_23.5 that one     
50 Jonah 2017-08-30 age_24   sandal       
51 Jonah 2017-08-30 age_12   bye bye      
52 Jonah 2017-08-30 age_12.5 &lt;NA&gt;         
53 Jonah 2017-08-30 age_13   &lt;NA&gt;         
54 Jonah 2017-08-30 age_13.5 &lt;NA&gt;         
55 Jonah 2017-08-30 age_14   &lt;NA&gt;         
56 Jonah 2017-08-30 age_14.5 &lt;NA&gt;         
57 Jonah 2017-08-30 age_15   &lt;NA&gt;         
58 Jonah 2017-08-30 age_15.5 beep         
59 Jonah 2017-08-30 age_16   hi           
60 Jonah 2017-08-30 age_16.5 box          
61 Jonah 2017-08-30 age_17   night-night  
62 Jonah 2017-08-30 age_17.5 jacket       
63 Jonah 2017-08-30 age_18   dinosaur     
64 Jonah 2017-08-30 age_18.5 wow          
65 Jonah 2017-08-30 age_19   snack/food   
# … with 1,210 more rows
```
]

---
count: false
 

.panel1-pivotlong-rotate[

```r
ds &lt;- read_csv('data_cleaned/vocab_annoying_headers.csv') %&gt;%
  mutate(id = "Jonah", dob = as.Date("2017-08-30"), .before = "age_12")
*ds %&gt;% pivot_longer(-(id:dob), names_to = "age", names_prefix = "age_", values_to = "word") %&gt;% print(n = 65)
```
]
 
.panel2-pivotlong-rotate[

```
# A tibble: 1,275 × 4
   id    dob        age   word         
   &lt;chr&gt; &lt;date&gt;     &lt;chr&gt; &lt;chr&gt;        
 1 Jonah 2017-08-30 12    book         
 2 Jonah 2017-08-30 12.5  dad          
 3 Jonah 2017-08-30 13    &lt;NA&gt;         
 4 Jonah 2017-08-30 13.5  cat          
 5 Jonah 2017-08-30 14    baby         
 6 Jonah 2017-08-30 14.5  socks/shoes  
 7 Jonah 2017-08-30 15    banana       
 8 Jonah 2017-08-30 15.5  cheese       
 9 Jonah 2017-08-30 16    shoes        
10 Jonah 2017-08-30 16.5  monkey       
11 Jonah 2017-08-30 17    hello        
12 Jonah 2017-08-30 17.5  bear         
13 Jonah 2017-08-30 18    milk/drink   
14 Jonah 2017-08-30 18.5  cleanup      
15 Jonah 2017-08-30 19    grandpa      
16 Jonah 2017-08-30 19.5  mouth        
17 Jonah 2017-08-30 20    coffee       
18 Jonah 2017-08-30 20.5  agua         
19 Jonah 2017-08-30 21    octopus      
20 Jonah 2017-08-30 21.5  (wrist) watch
21 Jonah 2017-08-30 22    shower       
22 Jonah 2017-08-30 22.5  hyena        
23 Jonah 2017-08-30 23    heart        
24 Jonah 2017-08-30 23.5  singing      
25 Jonah 2017-08-30 24    top          
26 Jonah 2017-08-30 12    ball         
27 Jonah 2017-08-30 12.5  &lt;NA&gt;         
28 Jonah 2017-08-30 13    &lt;NA&gt;         
29 Jonah 2017-08-30 13.5  &lt;NA&gt;         
30 Jonah 2017-08-30 14    &lt;NA&gt;         
31 Jonah 2017-08-30 14.5  dog (animal) 
32 Jonah 2017-08-30 15    llama        
33 Jonah 2017-08-30 15.5  turkey       
34 Jonah 2017-08-30 16    berry        
35 Jonah 2017-08-30 16.5  apple        
36 Jonah 2017-08-30 17    oh no        
37 Jonah 2017-08-30 17.5  go           
38 Jonah 2017-08-30 18    car          
39 Jonah 2017-08-30 18.5  that         
40 Jonah 2017-08-30 19    more         
41 Jonah 2017-08-30 19.5  peacock      
42 Jonah 2017-08-30 20    cup          
43 Jonah 2017-08-30 20.5  hide         
44 Jonah 2017-08-30 21    too          
45 Jonah 2017-08-30 21.5  blanket      
46 Jonah 2017-08-30 22    peanut butter
47 Jonah 2017-08-30 22.5  running      
48 Jonah 2017-08-30 23    empty        
49 Jonah 2017-08-30 23.5  that one     
50 Jonah 2017-08-30 24    sandal       
51 Jonah 2017-08-30 12    bye bye      
52 Jonah 2017-08-30 12.5  &lt;NA&gt;         
53 Jonah 2017-08-30 13    &lt;NA&gt;         
54 Jonah 2017-08-30 13.5  &lt;NA&gt;         
55 Jonah 2017-08-30 14    &lt;NA&gt;         
56 Jonah 2017-08-30 14.5  &lt;NA&gt;         
57 Jonah 2017-08-30 15    &lt;NA&gt;         
58 Jonah 2017-08-30 15.5  beep         
59 Jonah 2017-08-30 16    hi           
60 Jonah 2017-08-30 16.5  box          
61 Jonah 2017-08-30 17    night-night  
62 Jonah 2017-08-30 17.5  jacket       
63 Jonah 2017-08-30 18    dinosaur     
64 Jonah 2017-08-30 18.5  wow          
65 Jonah 2017-08-30 19    snack/food   
# … with 1,210 more rows
```
]

---
count: false
 

.panel1-pivotlong-rotate[

```r
ds &lt;- read_csv('data_cleaned/vocab_annoying_headers.csv') %&gt;%
  mutate(id = "Jonah", dob = as.Date("2017-08-30"), .before = "age_12")
*ds %&gt;% pivot_longer(-(id:dob), names_to = "age", values_to = "word", values_drop_na = T, names_prefix = "age_") %&gt;% print(n = 65)
```
]
 
.panel2-pivotlong-rotate[

```
# A tibble: 440 × 4
   id    dob        age   word         
   &lt;chr&gt; &lt;date&gt;     &lt;chr&gt; &lt;chr&gt;        
 1 Jonah 2017-08-30 12    book         
 2 Jonah 2017-08-30 12.5  dad          
 3 Jonah 2017-08-30 13.5  cat          
 4 Jonah 2017-08-30 14    baby         
 5 Jonah 2017-08-30 14.5  socks/shoes  
 6 Jonah 2017-08-30 15    banana       
 7 Jonah 2017-08-30 15.5  cheese       
 8 Jonah 2017-08-30 16    shoes        
 9 Jonah 2017-08-30 16.5  monkey       
10 Jonah 2017-08-30 17    hello        
11 Jonah 2017-08-30 17.5  bear         
12 Jonah 2017-08-30 18    milk/drink   
13 Jonah 2017-08-30 18.5  cleanup      
14 Jonah 2017-08-30 19    grandpa      
15 Jonah 2017-08-30 19.5  mouth        
16 Jonah 2017-08-30 20    coffee       
17 Jonah 2017-08-30 20.5  agua         
18 Jonah 2017-08-30 21    octopus      
19 Jonah 2017-08-30 21.5  (wrist) watch
20 Jonah 2017-08-30 22    shower       
21 Jonah 2017-08-30 22.5  hyena        
22 Jonah 2017-08-30 23    heart        
23 Jonah 2017-08-30 23.5  singing      
24 Jonah 2017-08-30 24    top          
25 Jonah 2017-08-30 12    ball         
26 Jonah 2017-08-30 14.5  dog (animal) 
27 Jonah 2017-08-30 15    llama        
28 Jonah 2017-08-30 15.5  turkey       
29 Jonah 2017-08-30 16    berry        
30 Jonah 2017-08-30 16.5  apple        
31 Jonah 2017-08-30 17    oh no        
32 Jonah 2017-08-30 17.5  go           
33 Jonah 2017-08-30 18    car          
34 Jonah 2017-08-30 18.5  that         
35 Jonah 2017-08-30 19    more         
36 Jonah 2017-08-30 19.5  peacock      
37 Jonah 2017-08-30 20    cup          
38 Jonah 2017-08-30 20.5  hide         
39 Jonah 2017-08-30 21    too          
40 Jonah 2017-08-30 21.5  blanket      
41 Jonah 2017-08-30 22    peanut butter
42 Jonah 2017-08-30 22.5  running      
43 Jonah 2017-08-30 23    empty        
44 Jonah 2017-08-30 23.5  that one     
45 Jonah 2017-08-30 24    sandal       
46 Jonah 2017-08-30 12    bye bye      
47 Jonah 2017-08-30 15.5  beep         
48 Jonah 2017-08-30 16    hi           
49 Jonah 2017-08-30 16.5  box          
50 Jonah 2017-08-30 17    night-night  
51 Jonah 2017-08-30 17.5  jacket       
52 Jonah 2017-08-30 18    dinosaur     
53 Jonah 2017-08-30 18.5  wow          
54 Jonah 2017-08-30 19    snack/food   
55 Jonah 2017-08-30 19.5  wash         
56 Jonah 2017-08-30 20    stroller     
57 Jonah 2017-08-30 20.5  shark        
58 Jonah 2017-08-30 21    grandma      
59 Jonah 2017-08-30 21.5  face         
60 Jonah 2017-08-30 22    lemon        
61 Jonah 2017-08-30 22.5  potty        
62 Jonah 2017-08-30 23    the end      
63 Jonah 2017-08-30 23.5  over there   
64 Jonah 2017-08-30 24    make         
65 Jonah 2017-08-30 16    diaper       
# … with 375 more rows
```
]

&lt;style&gt;
.panel1-pivotlong-rotate {
  color: black;
  width: 91.875%;
  hight: 32%;
  float: none;
  padding-left: 1%;
  font-size: 80%
}
.panel2-pivotlong-rotate {
  color: black;
  width: 6.125%;
  hight: 32%;
  float: none;
  padding-left: 1%;
  font-size: 80%
}
.panel3-pivotlong-rotate {
  color: black;
  width: NA%;
  hight: 33%;
  float: none;
  padding-left: 1%;
  font-size: 80%
}
&lt;/style&gt;






---
# Types of untidy data: Multiple variables in one column

- Mixing types in the same column
- No meaningful summary of “value”

```r
print(ds)
```

```
# A tibble: 84 × 3
   filename                field       value
   &lt;chr&gt;                   &lt;chr&gt;       &lt;chr&gt;
 1 data_headers/6191_1.txt Participant 6191 
 2 data_headers/6191_1.txt Age         25   
 3 data_headers/6191_1.txt Sex         male 
 4 data_headers/6191_1.txt Order       1    
 5 data_headers/6191_1.txt FirstSpeed  4    
 6 data_headers/6191_1.txt Block       1    
 7 data_headers/6191_1.txt speed       4    
 8 data_headers/6191_2.txt Participant 6191 
 9 data_headers/6191_2.txt Age         25   
10 data_headers/6191_2.txt Sex         male 
# … with 74 more rows
```
---
#Solution: tidyr's `pivot_wider()`


```r
ds &lt;- ds %&gt;% pivot_wider(id_cols = "filename", 
                         names_from = "field", 
                         values_from = "value")
ds
```

```
# A tibble: 12 × 8
   filename                Participant Age   Sex   Order FirstSpeed Block speed
   &lt;chr&gt;                   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;
 1 data_headers/6191_1.txt 6191        25    male  1     4          1     4    
 2 data_headers/6191_2.txt 6191        25    male  1     4          2     7    
 3 data_headers/6191_3.txt 6191        25    male  1     4          3     4    
 4 data_headers/6191_4.txt 6191        25    male  1     4          4     7    
 5 data_headers/6191_5.txt 6191        25    male  1     4          5     4    
 6 data_headers/6191_6.txt 6191        25    male  1     4          6     7    
 7 data_headers/6192_1.txt 6192        21    male  2     4          1     4    
 8 data_headers/6192_2.txt 6192        21    male  2     4          2     7    
 9 data_headers/6192_3.txt 6192        21    male  2     4          3     4    
10 data_headers/6192_4.txt 6192        21    male  2     4          4     7    
11 data_headers/6192_5.txt 6192        21    male  2     4          5     4    
12 data_headers/6192_6.txt 6192        21    male  2     4          6     7    
```
---
# Types of untidy data: Multiple variables in each cell
- Solution: tidyr's `separate()` function splits delimited text into separate cells

```r
ds %&gt;% separate(filename, into = c("dir_part1", "dir_part2", "ppt_file","ppt_block","exten"))
```

```
# A tibble: 12 × 12
   dir_part1 dir_part2 ppt_file ppt_block exten Participant Age   Sex   Order
   &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;
 1 data      headers   6191     1         txt   6191        25    male  1    
 2 data      headers   6191     2         txt   6191        25    male  1    
 3 data      headers   6191     3         txt   6191        25    male  1    
 4 data      headers   6191     4         txt   6191        25    male  1    
 5 data      headers   6191     5         txt   6191        25    male  1    
 6 data      headers   6191     6         txt   6191        25    male  1    
 7 data      headers   6192     1         txt   6192        21    male  2    
 8 data      headers   6192     2         txt   6192        21    male  2    
 9 data      headers   6192     3         txt   6192        21    male  2    
10 data      headers   6192     4         txt   6192        21    male  2    
11 data      headers   6192     5         txt   6192        21    male  2    
12 data      headers   6192     6         txt   6192        21    male  2    
# … with 3 more variables: FirstSpeed &lt;chr&gt;, Block &lt;chr&gt;, speed &lt;chr&gt;
```

---
# Types of untidy data: Multiple variables in each cell
- Solution: tidyr's `separate()` function splits delimited text into separate cells

```r
ds %&gt;% separate(filename, into = c(NA, NA, "ppt_file","ppt_block",NA))
```

```
# A tibble: 12 × 9
   ppt_file ppt_block Participant Age   Sex   Order FirstSpeed Block speed
   &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;
 1 6191     1         6191        25    male  1     4          1     4    
 2 6191     2         6191        25    male  1     4          2     7    
 3 6191     3         6191        25    male  1     4          3     4    
 4 6191     4         6191        25    male  1     4          4     7    
 5 6191     5         6191        25    male  1     4          5     4    
 6 6191     6         6191        25    male  1     4          6     7    
 7 6192     1         6192        21    male  2     4          1     4    
 8 6192     2         6192        21    male  2     4          2     7    
 9 6192     3         6192        21    male  2     4          3     4    
10 6192     4         6192        21    male  2     4          4     7    
11 6192     5         6192        21    male  2     4          5     4    
12 6192     6         6192        21    male  2     4          6     7    
```

---
# Types of untidy data: Multiple variables in each cell
- Solution: tidyr's `separate()` function splits delimited text into separate cells

```r
ds %&gt;% separate(filename, into = c(NA, NA, "ppt_file","ppt_block",NA)) %&gt;% 
  mutate(across(-Sex, as.numeric))
```

```
# A tibble: 12 × 9
   ppt_file ppt_block Participant   Age Sex   Order FirstSpeed Block speed
      &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
 1     6191         1        6191    25 male      1          4     1     4
 2     6191         2        6191    25 male      1          4     2     7
 3     6191         3        6191    25 male      1          4     3     4
 4     6191         4        6191    25 male      1          4     4     7
 5     6191         5        6191    25 male      1          4     5     4
 6     6191         6        6191    25 male      1          4     6     7
 7     6192         1        6192    21 male      2          4     1     4
 8     6192         2        6192    21 male      2          4     2     7
 9     6192         3        6192    21 male      2          4     3     4
10     6192         4        6192    21 male      2          4     4     7
11     6192         5        6192    21 male      2          4     5     4
12     6192         6        6192    21 male      2          4     6     7
```

---
# Types of untidy data: Multiple variables in each cell
- Solution: tidyr's `separate()` function splits delimited text into separate cells

```r
ds %&gt;% separate(filename, into = c("dir","file"), sep = "/")
```

```
# A tibble: 12 × 9
   dir          file       Participant Age   Sex   Order FirstSpeed Block speed
   &lt;chr&gt;        &lt;chr&gt;      &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;
 1 data_headers 6191_1.txt 6191        25    male  1     4          1     4    
 2 data_headers 6191_2.txt 6191        25    male  1     4          2     7    
 3 data_headers 6191_3.txt 6191        25    male  1     4          3     4    
 4 data_headers 6191_4.txt 6191        25    male  1     4          4     7    
 5 data_headers 6191_5.txt 6191        25    male  1     4          5     4    
 6 data_headers 6191_6.txt 6191        25    male  1     4          6     7    
 7 data_headers 6192_1.txt 6192        21    male  2     4          1     4    
 8 data_headers 6192_2.txt 6192        21    male  2     4          2     7    
 9 data_headers 6192_3.txt 6192        21    male  2     4          3     4    
10 data_headers 6192_4.txt 6192        21    male  2     4          4     7    
11 data_headers 6192_5.txt 6192        21    male  2     4          5     4    
12 data_headers 6192_6.txt 6192        21    male  2     4          6     7    
```

---
# Joining data

- Data frames can be joined in three main ways
  * `bind_rows` means adding rows (where all of the columns are the same)
  * `bind_cols` means adding columns (where all observations are the same)
  * Matching joins, where columns are added from one data frame to another based on matching key information (`full_join`, `inner_join`, `left_join`,`right_join`)
  

---
# Binding Columns


```r
star_wars_numeric &lt;- starwars %&gt;% select(where(is.numeric)) #87x3
star_wars_char &lt;- starwars %&gt;% select(where(is.character)) #87x8
star_wars_combined &lt;- bind_cols(star_wars_numeric, star_wars_char) #87x11
star_wars_combined
```

```
# A tibble: 87 × 11
   height  mass birth_year name    hair_color  skin_color eye_color sex   gender
    &lt;int&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt; 
 1    172    77       19   Luke S… blond       fair       blue      male  mascu…
 2    167    75      112   C-3PO   &lt;NA&gt;        gold       yellow    none  mascu…
 3     96    32       33   R2-D2   &lt;NA&gt;        white, bl… red       none  mascu…
 4    202   136       41.9 Darth … none        white      yellow    male  mascu…
 5    150    49       19   Leia O… brown       light      brown     fema… femin…
 6    178   120       52   Owen L… brown, grey light      blue      male  mascu…
 7    165    75       47   Beru W… brown       light      blue      fema… femin…
 8     97    32       NA   R5-D4   &lt;NA&gt;        white, red red       none  mascu…
 9    183    84       24   Biggs … black       light      brown     male  mascu…
10    182    77       57   Obi-Wa… auburn, wh… fair       blue-gray male  mascu…
# … with 77 more rows, and 2 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;
```

---
# Binding Rows


```r
s1 &lt;- starwars %&gt;% slice_sample(n = 2) #2x14
s2 &lt;- starwars %&gt;% slice_sample(n = 2) #2x14
s3 &lt;- starwars %&gt;% slice_sample(n = 2) #2x14
star_wars_combined &lt;- bind_rows(s1, s2, s3) #6x14
star_wars_combined
```

```
# A tibble: 6 × 14
  name     height  mass hair_color skin_color  eye_color birth_year sex   gender
  &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; 
1 Bail Pr…    191    NA black      tan         brown             67 male  mascu…
2 Ben Qua…    163    65 none       grey, gree… orange            NA male  mascu…
3 Sly Moo…    178    48 none       pale        white             NA &lt;NA&gt;  &lt;NA&gt;  
4 Tion Me…    206    80 none       grey        black             NA male  mascu…
5 Mas Ame…    196    NA none       blue        blue              NA male  mascu…
6 Sebulba     112    40 none       grey, red   orange            NA male  mascu…
# … with 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,
#   vehicles &lt;list&gt;, starships &lt;list&gt;
```

---
count: false
 
# Joining by key value
.panel1-join-rotate[

```r
fnames &lt;- list.files(path = "data_headers", full.names = T)
header &lt;- read_delim(fnames, col_names = c("field", "value"), col_types = c("cc"), delim = " ", n_max = 7, id = "filename") %&gt;% pivot_wider(id_cols = "filename", names_from = "field", values_from = "value")
trials &lt;- read_tsv(fnames, col_names = c("trial_num", "speed_actual", "speed_resp", "correct"), skip = 8, id = "filename")
*header
```
]
 
.panel2-join-rotate[

```
# A tibble: 12 × 8
   filename                Participant Age   Sex   Order FirstSpeed Block speed
   &lt;chr&gt;                   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;
 1 data_headers/6191_1.txt 6191        25    male  1     4          1     4    
 2 data_headers/6191_2.txt 6191        25    male  1     4          2     7    
 3 data_headers/6191_3.txt 6191        25    male  1     4          3     4    
 4 data_headers/6191_4.txt 6191        25    male  1     4          4     7    
 5 data_headers/6191_5.txt 6191        25    male  1     4          5     4    
 6 data_headers/6191_6.txt 6191        25    male  1     4          6     7    
 7 data_headers/6192_1.txt 6192        21    male  2     4          1     4    
 8 data_headers/6192_2.txt 6192        21    male  2     4          2     7    
 9 data_headers/6192_3.txt 6192        21    male  2     4          3     4    
10 data_headers/6192_4.txt 6192        21    male  2     4          4     7    
11 data_headers/6192_5.txt 6192        21    male  2     4          5     4    
12 data_headers/6192_6.txt 6192        21    male  2     4          6     7    
```
]

---
count: false
 
# Joining by key value
.panel1-join-rotate[

```r
fnames &lt;- list.files(path = "data_headers", full.names = T)
header &lt;- read_delim(fnames, col_names = c("field", "value"), col_types = c("cc"), delim = " ", n_max = 7, id = "filename") %&gt;% pivot_wider(id_cols = "filename", names_from = "field", values_from = "value")
trials &lt;- read_tsv(fnames, col_names = c("trial_num", "speed_actual", "speed_resp", "correct"), skip = 8, id = "filename")
*trials
```
]
 
.panel2-join-rotate[

```
# A tibble: 240 × 5
   filename                trial_num speed_actual speed_resp correct
   &lt;chr&gt;                       &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;      &lt;lgl&gt;  
 1 data_headers/6191_1.txt         1 fas          slower     FALSE  
 2 data_headers/6191_1.txt         2 fas          faster     TRUE   
 3 data_headers/6191_1.txt         3 fas          faster     TRUE   
 4 data_headers/6191_1.txt         4 fas          slower     FALSE  
 5 data_headers/6191_1.txt         5 fas          faster     TRUE   
 6 data_headers/6191_1.txt         6 slo          slower     TRUE   
 7 data_headers/6191_1.txt         7 fas          faster     TRUE   
 8 data_headers/6191_1.txt         8 slo          slower     TRUE   
 9 data_headers/6191_1.txt         9 slo          slower     TRUE   
10 data_headers/6191_1.txt        10 slo          faster     FALSE  
# … with 230 more rows
```
]

---
count: false
 
# Joining by key value
.panel1-join-rotate[

```r
fnames &lt;- list.files(path = "data_headers", full.names = T)
header &lt;- read_delim(fnames, col_names = c("field", "value"), col_types = c("cc"), delim = " ", n_max = 7, id = "filename") %&gt;% pivot_wider(id_cols = "filename", names_from = "field", values_from = "value")
trials &lt;- read_tsv(fnames, col_names = c("trial_num", "speed_actual", "speed_resp", "correct"), skip = 8, id = "filename")
*left_join(header, trials, by = "filename")
```
]
 
.panel2-join-rotate[

```
# A tibble: 240 × 12
   filename       Participant Age   Sex   Order FirstSpeed Block speed trial_num
   &lt;chr&gt;          &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;
 1 data_headers/… 6191        25    male  1     4          1     4             1
 2 data_headers/… 6191        25    male  1     4          1     4             2
 3 data_headers/… 6191        25    male  1     4          1     4             3
 4 data_headers/… 6191        25    male  1     4          1     4             4
 5 data_headers/… 6191        25    male  1     4          1     4             5
 6 data_headers/… 6191        25    male  1     4          1     4             6
 7 data_headers/… 6191        25    male  1     4          1     4             7
 8 data_headers/… 6191        25    male  1     4          1     4             8
 9 data_headers/… 6191        25    male  1     4          1     4             9
10 data_headers/… 6191        25    male  1     4          1     4            10
# … with 230 more rows, and 3 more variables: speed_actual &lt;chr&gt;,
#   speed_resp &lt;chr&gt;, correct &lt;lgl&gt;
```
]

---
count: false
 
# Joining by key value
.panel1-join-rotate[

```r
fnames &lt;- list.files(path = "data_headers", full.names = T)
header &lt;- read_delim(fnames, col_names = c("field", "value"), col_types = c("cc"), delim = " ", n_max = 7, id = "filename") %&gt;% pivot_wider(id_cols = "filename", names_from = "field", values_from = "value")
trials &lt;- read_tsv(fnames, col_names = c("trial_num", "speed_actual", "speed_resp", "correct"), skip = 8, id = "filename")
*left_join(slice_sample(header, n = 5), trials, by = "filename")
```
]
 
.panel2-join-rotate[

```
# A tibble: 100 × 12
   filename       Participant Age   Sex   Order FirstSpeed Block speed trial_num
   &lt;chr&gt;          &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;
 1 data_headers/… 6191        25    male  1     4          2     7             1
 2 data_headers/… 6191        25    male  1     4          2     7             2
 3 data_headers/… 6191        25    male  1     4          2     7             3
 4 data_headers/… 6191        25    male  1     4          2     7             4
 5 data_headers/… 6191        25    male  1     4          2     7             5
 6 data_headers/… 6191        25    male  1     4          2     7             6
 7 data_headers/… 6191        25    male  1     4          2     7             7
 8 data_headers/… 6191        25    male  1     4          2     7             8
 9 data_headers/… 6191        25    male  1     4          2     7             9
10 data_headers/… 6191        25    male  1     4          2     7            10
# … with 90 more rows, and 3 more variables: speed_actual &lt;chr&gt;,
#   speed_resp &lt;chr&gt;, correct &lt;lgl&gt;
```
]

---
count: false
 
# Joining by key value
.panel1-join-rotate[

```r
fnames &lt;- list.files(path = "data_headers", full.names = T)
header &lt;- read_delim(fnames, col_names = c("field", "value"), col_types = c("cc"), delim = " ", n_max = 7, id = "filename") %&gt;% pivot_wider(id_cols = "filename", names_from = "field", values_from = "value")
trials &lt;- read_tsv(fnames, col_names = c("trial_num", "speed_actual", "speed_resp", "correct"), skip = 8, id = "filename")
*left_join(slice_sample(trials, n = 5), header, by = "filename")
```
]
 
.panel2-join-rotate[

```
# A tibble: 5 × 12
  filename     trial_num speed_actual speed_resp correct Participant Age   Sex  
  &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;      &lt;lgl&gt;   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;
1 data_header…        11 fas          faster     TRUE    6192        21    male 
2 data_header…        12 slo          faster     FALSE   6192        21    male 
3 data_header…        16 fas          slower     FALSE   6192        21    male 
4 data_header…         2 slo          slower     TRUE    6192        21    male 
5 data_header…         1 slo          slower     TRUE    6191        25    male 
# … with 4 more variables: Order &lt;chr&gt;, FirstSpeed &lt;chr&gt;, Block &lt;chr&gt;,
#   speed &lt;chr&gt;
```
]

&lt;style&gt;
.panel1-join-rotate {
  color: black;
  width: 87.1111111111111%;
  hight: 32%;
  float: none;
  padding-left: 1%;
  font-size: 80%
}
.panel2-join-rotate {
  color: black;
  width: 10.8888888888889%;
  hight: 32%;
  float: none;
  padding-left: 1%;
  font-size: 80%
}
.panel3-join-rotate {
  color: black;
  width: NA%;
  hight: 33%;
  float: none;
  padding-left: 1%;
  font-size: 80%
}
&lt;/style&gt;





&lt;!-- adjust font size and other formatting defs in this css code chunk --&gt;
&lt;style type="text/css"&gt;
.remark-code{line-height: 1; font-size: 70%}

@media print {
  .has-continuation {
    display: block;
  }
}

code.r.hljs.remark-code{
  position: relative;
  overflow-x: hidden;
}

.remark-slide-number {
  opacity: 0; /* default: 0.5 */
}

.content-box { 
    box-sizing: border-box;
    background-color: #e2e2e2;
}
.content-box-blue,
.content-box-gray,
.content-box-grey,
.content-box-army,
.content-box-green,
.content-box-purple,
.content-box-red,
.content-box-yellow {
  box-sizing: border-box;
  border-radius: 15px;
  margin: 0 0 15px;
  overflow: hidden;
  padding: 0px 20px 0px 20px;
  width: 100%;
}
.content-box-blue { background-color: #F0F8FF; }
.content-box-gray { background-color: #e2e2e2; }
.content-box-grey {	background-color: #F5F5F5; }
.content-box-army {	background-color: #737a36; }
.content-box-green { background-color: #d9edc2; }
.content-box-purple { background-color: #e2e2f9; }
.content-box-red { background-color: #ffcccc; }
.content-box-yellow { background-color: #fef5c4; }
.content-box-blue .remark-inline-code,
.content-box-blue .remark-inline-code,
.content-box-gray .remark-inline-code,
.content-box-grey .remark-inline-code,
.content-box-army .remark-inline-code,
.content-box-green .remark-inline-code,
.content-box-purple .remark-inline-code,
.content-box-red .remark-inline-code,
.content-box-yellow .remark-inline-code { 
  background: none;
}

.scroll-box-8 {
  height:8em;
  overflow-y: scroll;
}
.scroll-box-10 {
  height:10em;
  overflow-y: scroll;
}
.scroll-box-12 {
  height:12em;
  overflow-y: scroll;
}
.scroll-box-14 {
  height:14em;
  overflow-y: scroll;
}
.scroll-box-16 {
  height:16em;
  overflow-y: scroll;
}
.scroll-box-18 {
  height:18em;
  overflow-y: scroll;
}
.scroll-box-20 {
  height:20em;
  overflow-y: scroll;
}
.scroll-output {
  height: 90%;
  overflow-y: scroll;
}
}

/************************
 * Font size and colours
 ************************/

/*      LaTeX style       */
.Large       , .Large .remark-code, .Large .remark-inline-code { font-size: 144%; }
.large       , .large .remark-code, .large .remark-inline-code { font-size: 120%; }
.small       , .small .remark-code, .small .remark-inline-code { font-size: 90%; }
.footnotesize, .footnotesize .remark-code, .footnotesize .remark-inline-code { font-size: 80%; }
.scriptsize  , .scriptsize .remark-code, .scriptsize .remark-inline-code { font-size: 70%; }
.tiny        , .tiny .remark-code, .tiny .remark-inline-code { font-size: 60%; }

/* or you can be more specific */
.font10 , .code10 .remark-code, .code10 .remark-inline-code{ font-size: 10%; }
.font20 , .code20 .remark-code, .code20 .remark-inline-code{ font-size: 20%; }
.font30 , .code30 .remark-code, .code30 .remark-inline-code{ font-size: 30%; }
.font40 , .code40 .remark-code, .code40 .remark-inline-code{ font-size: 40%; }
.font50 , .code50 .remark-code, .code50 .remark-inline-code{ font-size: 50%; }
.font60 , .code60 .remark-code, .code60 .remark-inline-code{ font-size: 60%; }
.font70 , .code70 .remark-code, .code70 .remark-inline-code{ font-size: 70%; }
.font75 , .code75 .remark-code, .code75 .remark-inline-code{ font-size: 75%; }
.font80 , .code80 .remark-code, .code80 .remark-inline-code{ font-size: 80%; }
.font90 , .code90 .remark-code, .code90 .remark-inline-code{ font-size: 90%; }
.font100, .code100 .remark-code, .code100 .remark-inline-code{ font-size: 100%; }
.font110, .code110 .remark-code, .code110 .remark-inline-code{ font-size: 110%; }
.font120, .code120 .remark-code, .code120 .remark-inline-code{ font-size: 120%; }
.font130, .code130 .remark-code, .code130 .remark-inline-code{ font-size: 130%; }
.font140, .code140 .remark-code, .code140 .remark-inline-code{ font-size: 140%; }
.font150, .code150 .remark-code, .code150 .remark-inline-code{ font-size: 150%; }
.font160, .code160 .remark-code, .code160 .remark-inline-code{ font-size: 160%; }
.font170, .code170 .remark-code, .code170 .remark-inline-code{ font-size: 170%; }
.font175, .code175 .remark-code, .code175 .remark-inline-code{ font-size: 175%; }
.font180, .code180 .remark-code, .code180 .remark-inline-code{ font-size: 180%; }
.font190, .code190 .remark-code, .code190 .remark-inline-code{ font-size: 190%; }
.font200, .code200 .remark-code, .code200 .remark-inline-code{ font-size: 200%; }

.brand-red { color: #e64626; }
.brand-blue { color: #0148A4; }
.brand-yellow { color: #FFB800; }
.brand-charcoal {color: #424242; }
.brand-gray {color: #F1F1F1;}
.brand-grey {color: #F1F1F1;}
.black { color: black; }
.white { color: white; }
.red { color: red; }
.blue { color: blue; }
.green { color: green; }
.yellow { color: yellow; }
.orange { color: orange; }
.purple { color: purple; }
.gray { color: gray; }
.grey { color: gray; }

.bold { font-weight: bold; }
.bolder { font-weight: bolder; }
&lt;/style&gt;

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"navigation": {
"scroll": false
}
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
